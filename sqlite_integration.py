#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SQLite ê¸°ë°˜ ë°ì´í„°ë² ì´ìŠ¤ í†µí•©
"""
import sys
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

import json
import logging
from datetime import datetime
from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, Text, ForeignKey
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship, sessionmaker

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# SQLite ê¸°ë°˜ ëª¨ë¸ ì •ì˜
Base = declarative_base()

class PokerSite(Base):
    __tablename__ = 'poker_sites'
    
    id = Column(Integer, primary_key=True)
    name = Column(String(100), unique=True, nullable=False)
    url = Column(String(255))
    network = Column(String(100))
    created_at = Column(DateTime, default=datetime.utcnow)
    
    traffic_data = relationship('TrafficData', back_populates='site')
    news_items = relationship('NewsItem', back_populates='site')

class TrafficData(Base):
    __tablename__ = 'traffic_data'
    
    id = Column(Integer, primary_key=True)
    site_id = Column(Integer, ForeignKey('poker_sites.id'), nullable=False)
    cash_players = Column(Integer)
    tournament_players = Column(Integer)
    total_players = Column(Integer)
    seven_day_average = Column(Float)
    peak_players = Column(Integer)
    rank = Column(Integer)
    timestamp = Column(DateTime, default=datetime.utcnow)
    
    site = relationship('PokerSite', back_populates='traffic_data')

class NewsItem(Base):
    __tablename__ = 'news_items'
    
    id = Column(Integer, primary_key=True)
    site_id = Column(Integer, ForeignKey('poker_sites.id'))
    title = Column(String(500), nullable=False)
    url = Column(String(500), unique=True)
    content = Column(Text)
    author = Column(String(100))
    published_date = Column(DateTime)
    category = Column(String(50))
    scraped_at = Column(DateTime, default=datetime.utcnow)
    
    site = relationship('PokerSite', back_populates='news_items')

class CrawlLog(Base):
    __tablename__ = 'crawl_logs'
    
    id = Column(Integer, primary_key=True)
    source = Column(String(50), nullable=False)
    status = Column(String(20), nullable=False)
    items_scraped = Column(Integer, default=0)
    error_message = Column(Text)
    started_at = Column(DateTime, nullable=False)
    completed_at = Column(DateTime)

class SQLiteDataIntegrator:
    def __init__(self, db_path='poker_insight.db'):
        self.engine = create_engine(f'sqlite:///{db_path}')
        Base.metadata.create_all(self.engine)
        SessionLocal = sessionmaker(bind=self.engine)
        self.session = SessionLocal()
        
    def load_json_data(self, file_path):
        """JSON íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Error loading {file_path}: {str(e)}")
            return None
            
    def integrate_pokerscout_data(self):
        """PokerScout ë°ì´í„° í†µí•©"""
        logger.info("ğŸ¯ PokerScout ë°ì´í„° í†µí•© ì‹œì‘...")
        
        data = self.load_json_data('pokerscout_perfect_data.json')
        if not data:
            logger.error("PokerScout ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
        sites_added = 0
        traffic_records = 0
        
        try:
            for site_data in data['data']:
                # í¬ì»¤ ì‚¬ì´íŠ¸ ì €ì¥/ì—…ë°ì´íŠ¸
                site = self.session.query(PokerSite).filter_by(name=site_data['name']).first()
                if not site:
                    site = PokerSite(
                        name=site_data['name'],
                        network=site_data.get('network', 'Unknown')
                    )
                    self.session.add(site)
                    self.session.flush()
                    sites_added += 1
                    logger.info(f"  ìƒˆ ì‚¬ì´íŠ¸ ì¶”ê°€: {site.name}")
                    
                # íŠ¸ë˜í”½ ë°ì´í„° ì €ì¥
                traffic_data = TrafficData(
                    site_id=site.id,
                    cash_players=site_data.get('cash_players', 0),
                    tournament_players=site_data.get('tournament_players', 0),
                    total_players=site_data.get('players_online', 0),
                    seven_day_average=site_data.get('7_day_average', 0),
                    peak_players=site_data.get('peak_24h', 0),
                    rank=site_data.get('rank', 0),
                    timestamp=datetime.fromisoformat(data['timestamp'].replace('Z', '+00:00'))
                )
                self.session.add(traffic_data)
                traffic_records += 1
                
            # í¬ë¡¤ ë¡œê·¸ ì €ì¥
            crawl_log = CrawlLog(
                source='pokerscout',
                status='success',
                items_scraped=len(data['data']),
                started_at=datetime.fromisoformat(data['timestamp'].replace('Z', '+00:00')),
                completed_at=datetime.utcnow()
            )
            self.session.add(crawl_log)
            
            self.session.commit()
            
            logger.info(f"âœ… PokerScout ë°ì´í„° í†µí•© ì™„ë£Œ!")
            logger.info(f"  - ìƒˆ ì‚¬ì´íŠ¸: {sites_added}ê°œ")
            logger.info(f"  - íŠ¸ë˜í”½ ë ˆì½”ë“œ: {traffic_records}ê°œ")
            
            return True
            
        except Exception as e:
            logger.error(f"PokerScout ë°ì´í„° í†µí•© ì˜¤ë¥˜: {str(e)}")
            self.session.rollback()
            return False
            
    def integrate_pokernews_data(self):
        """PokerNews ë°ì´í„° í†µí•©"""
        logger.info("ğŸ“° PokerNews ë°ì´í„° í†µí•© ì‹œì‘...")
        
        data = self.load_json_data('pokernews_final_data.json')
        if not data:
            logger.error("PokerNews ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
        news_added = 0
        
        try:
            for article_data in data['data']:
                # ì¤‘ë³µ ì²´í¬
                existing = self.session.query(NewsItem).filter_by(url=article_data['url']).first()
                if existing:
                    continue
                    
                # ê´€ë ¨ ì‚¬ì´íŠ¸ ì°¾ê¸°
                site_id = None
                site_name = self.extract_site_from_title(article_data['title'])
                if site_name:
                    site = self.session.query(PokerSite).filter_by(name=site_name).first()
                    if site:
                        site_id = site.id
                        
                # ë‰´ìŠ¤ ì•„ì´í…œ ì €ì¥
                news_item = NewsItem(
                    site_id=site_id,
                    title=article_data['title'],
                    url=article_data['url'],
                    content=article_data.get('summary', ''),
                    author=self.clean_author_name(article_data.get('author', '')),
                    published_date=self.parse_news_date(article_data.get('date')),
                    category=article_data.get('category', 'general'),
                    scraped_at=datetime.fromisoformat(data['timestamp'].replace('Z', '+00:00'))
                )
                self.session.add(news_item)
                news_added += 1
                
            # í¬ë¡¤ ë¡œê·¸ ì €ì¥
            crawl_log = CrawlLog(
                source='pokernews',
                status='success',
                items_scraped=len(data['data']),
                started_at=datetime.fromisoformat(data['timestamp'].replace('Z', '+00:00')),
                completed_at=datetime.utcnow()
            )
            self.session.add(crawl_log)
            
            self.session.commit()
            
            logger.info(f"âœ… PokerNews ë°ì´í„° í†µí•© ì™„ë£Œ!")
            logger.info(f"  - ìƒˆ ë‰´ìŠ¤: {news_added}ê°œ")
            
            return True
            
        except Exception as e:
            logger.error(f"PokerNews ë°ì´í„° í†µí•© ì˜¤ë¥˜: {str(e)}")
            self.session.rollback()
            return False
            
    def extract_site_from_title(self, title):
        """ì œëª©ì—ì„œ í¬ì»¤ ì‚¬ì´íŠ¸ëª… ì¶”ì¶œ"""
        poker_sites = {
            'PokerStars': ['pokerstars', 'stars'],
            'GGNetwork': ['ggpoker', 'ggnetwork', 'gg poker'],
            '888poker': ['888poker', '888'],
            'partypoker': ['partypoker', 'party poker'],
            'WPT Global': ['wpt', 'world poker tour'],
            'WSOP': ['wsop', 'world series']
        }
        
        title_lower = title.lower()
        for site_name, keywords in poker_sites.items():
            if any(keyword in title_lower for keyword in keywords):
                return site_name
                
        return None
        
    def clean_author_name(self, author_text):
        """ì €ìëª… ì •ë¦¬"""
        if not author_text:
            return ''
            
        lines = author_text.split('\n')
        if lines:
            return lines[0].strip()
            
        return author_text.strip()
        
    def parse_news_date(self, date_str):
        """ë‰´ìŠ¤ ë‚ ì§œ íŒŒì‹±"""
        try:
            if date_str:
                return datetime.strptime(date_str, '%Y-%m-%d')
        except:
            pass
        return datetime.utcnow()
        
    def generate_analysis_report(self):
        """ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        logger.info("ğŸ“Š ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        try:
            # ê¸°ë³¸ í†µê³„
            total_sites = self.session.query(PokerSite).count()
            total_traffic_records = self.session.query(TrafficData).count()
            total_news = self.session.query(NewsItem).count()
            
            # TOP 10 í¬ì»¤ ì‚¬ì´íŠ¸ (íŠ¸ë˜í”½ ê¸°ì¤€)
            top_sites = self.session.query(PokerSite, TrafficData)\
                .join(TrafficData)\
                .order_by(TrafficData.total_players.desc())\
                .limit(10).all()
                
            # ìµœì‹  ë‰´ìŠ¤ (ìƒìœ„ 10ê°œ)
            latest_news = self.session.query(NewsItem)\
                .order_by(NewsItem.scraped_at.desc())\
                .limit(10).all()
                
            # ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤ í†µê³„
            from sqlalchemy import func
            news_by_category = self.session.query(
                NewsItem.category, func.count(NewsItem.id)
            ).group_by(NewsItem.category).all()
            
            report = {
                'generated_at': datetime.utcnow().isoformat(),
                'summary': {
                    'total_poker_sites': total_sites,
                    'total_traffic_records': total_traffic_records,
                    'total_news_articles': total_news
                },
                'top_poker_sites': [
                    {
                        'rank': i + 1,
                        'name': site.name,
                        'total_players': traffic.total_players,
                        'cash_players': traffic.cash_players,
                        'tournament_players': traffic.tournament_players,
                        '7_day_average': traffic.seven_day_average
                    }
                    for i, (site, traffic) in enumerate(top_sites)
                ],
                'latest_news': [
                    {
                        'title': news.title,
                        'category': news.category,
                        'author': news.author,
                        'published_date': news.published_date.isoformat() if news.published_date else None,
                        'url': news.url
                    }
                    for news in latest_news
                ],
                'news_by_category': {
                    category: count for category, count in news_by_category
                }
            }
            
            # ë¦¬í¬íŠ¸ ì €ì¥
            with open('analysis_report.json', 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
                
            return report
            
        except Exception as e:
            logger.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return None
            
    def display_summary(self):
        """ìš”ì•½ ì •ë³´ ì¶œë ¥"""
        try:
            total_sites = self.session.query(PokerSite).count()
            total_traffic = self.session.query(TrafficData).count()
            total_news = self.session.query(NewsItem).count()
            
            print(f"\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©:")
            print(f"  í¬ì»¤ ì‚¬ì´íŠ¸: {total_sites}ê°œ")
            print(f"  íŠ¸ë˜í”½ ë ˆì½”ë“œ: {total_traffic}ê°œ")
            print(f"  ë‰´ìŠ¤ ê¸°ì‚¬: {total_news}ê°œ")
            
            # TOP 5 ì‚¬ì´íŠ¸
            top_sites = self.session.query(PokerSite, TrafficData)\
                .join(TrafficData)\
                .order_by(TrafficData.total_players.desc())\
                .limit(5).all()
                
            print(f"\nğŸ† TOP 5 í¬ì»¤ ì‚¬ì´íŠ¸:")
            for i, (site, traffic) in enumerate(top_sites, 1):
                print(f"  {i}. {site.name}: {traffic.total_players:,}ëª…")
                
        except Exception as e:
            logger.error(f"ìš”ì•½ ì¶œë ¥ ì˜¤ë¥˜: {str(e)}")
            
    def close(self):
        """ì„¸ì…˜ ì¢…ë£Œ"""
        self.session.close()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”„ SQLite ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ì‹œì‘")
    print("="*50)
    
    integrator = SQLiteDataIntegrator()
    
    try:
        # 1. PokerScout ë°ì´í„° í†µí•©
        pokerscout_success = integrator.integrate_pokerscout_data()
        
        # 2. PokerNews ë°ì´í„° í†µí•©
        pokernews_success = integrator.integrate_pokernews_data()
        
        if pokerscout_success and pokernews_success:
            # 3. ìš”ì•½ ì •ë³´ ì¶œë ¥
            integrator.display_summary()
            
            # 4. ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
            report = integrator.generate_analysis_report()
            
            print(f"\nğŸ‰ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ì™„ë£Œ!")
            print(f"âœ… PokerScout ë°ì´í„° í†µí•© ì„±ê³µ")
            print(f"âœ… PokerNews ë°ì´í„° í†µí•© ì„±ê³µ")
            print(f"ğŸ“Š ë¶„ì„ ë¦¬í¬íŠ¸: analysis_report.json")
            print(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤: poker_insight.db")
            
            return True
        else:
            print(f"\nâš ï¸ ì¼ë¶€ ë°ì´í„° í†µí•© ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        logger.error(f"í†µí•© í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {str(e)}")
        return False
    finally:
        integrator.close()

if __name__ == "__main__":
    success = main()
    if success:
        print(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„: í¬ì»¤ íŠ¸ë˜í”½ ë¶„ì„ ê¸°ëŠ¥ ê°œë°œ ì¤€ë¹„ ì™„ë£Œ!")
    else:
        print(f"\nğŸ’€ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ì‹¤íŒ¨ - ë¬¸ì œ í•´ê²° í•„ìš”")