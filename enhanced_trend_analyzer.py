#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í–¥ìƒëœ í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ê¸° - ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ìˆ˜ì •
"""
import sys
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

import json
import logging
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import statistics
import sqlite3

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnhancedPokerTrendAnalyzer:
    def __init__(self, db_path='poker_insight.db'):
        self.db_path = db_path
        
    def get_db_connection(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        return sqlite3.connect(self.db_path)
        
    def analyze_current_market_data(self):
        """ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í˜„ì¬ ì‹œì¥ ë°ì´í„° ë¶„ì„"""
        logger.info("ğŸ† ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ì‹œì¥ ë¶„ì„...")
        
        try:
            conn = self.get_db_connection()
            cursor = conn.cursor()
            
            # í˜„ì¬ íŠ¸ë˜í”½ ë°ì´í„°
            query = """
            SELECT 
                ps.name,
                td.total_players,
                td.cash_players,
                td.tournament_players,
                td.seven_day_average,
                td.rank
            FROM poker_sites ps
            JOIN traffic_data td ON ps.id = td.site_id
            ORDER BY td.total_players DESC
            LIMIT 20
            """
            
            cursor.execute(query)
            sites_data = cursor.fetchall()
            
            if not sites_data:
                logger.warning("ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {}
                
            total_players = sum(row[1] for row in sites_data)
            total_cash = sum(row[2] for row in sites_data)
            total_tournaments = sum(row[3] for row in sites_data)
            
            # í™œì„± ì‚¬ì´íŠ¸ ìˆ˜
            active_sites = len([row for row in sites_data if row[1] > 0])
            
            # ìƒìœ„ 3ê°œ ì‚¬ì´íŠ¸ ì ìœ ìœ¨
            top3_share = sum(row[1] for row in sites_data[:3]) / total_players * 100 if total_players > 0 else 0
            
            market_analysis = {
                'total_players_online': total_players,
                'total_cash_players': total_cash,
                'total_tournament_players': total_tournaments,
                'active_sites_count': active_sites,
                'total_sites_tracked': len(sites_data),
                'top3_market_share': round(top3_share, 1),
                'cash_tournament_ratio': round((total_cash / total_tournaments) * 100, 1) if total_tournaments > 0 else 0,
                'market_leader': sites_data[0][0] if sites_data else 'N/A',
                'market_leader_share': round((sites_data[0][1] / total_players) * 100, 1) if sites_data and total_players > 0 else 0,
                'top_sites_data': [
                    {
                        'name': row[0],
                        'players': row[1],
                        'cash_players': row[2],
                        'tournament_players': row[3],
                        '7_day_avg': row[4],
                        'rank': row[5]
                    }
                    for row in sites_data[:10]
                ]
            }
            
            conn.close()
            return market_analysis
            
        except Exception as e:
            logger.error(f"ì‹œì¥ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {}
            
    def analyze_news_data(self):
        """ì‹¤ì œ ë‰´ìŠ¤ ë°ì´í„° ë¶„ì„"""
        logger.info("ğŸ“° ì‹¤ì œ ë‰´ìŠ¤ ë°ì´í„° ë¶„ì„...")
        
        try:
            conn = self.get_db_connection()
            cursor = conn.cursor()
            
            # ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ
            query = """
            SELECT title, content, category, author, published_date
            FROM news_items
            ORDER BY scraped_at DESC
            LIMIT 100
            """
            
            cursor.execute(query)
            news_data = cursor.fetchall()
            
            if not news_data:
                logger.warning("ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {}
                
            # í‚¤ì›Œë“œ ë¶„ì„
            keywords_analysis = self.analyze_keywords_enhanced(news_data)
            
            # ì¹´í…Œê³ ë¦¬ ë¶„ì„
            categories_analysis = self.analyze_categories_enhanced(news_data)
            
            # ì €ì ë¶„ì„
            authors_analysis = self.analyze_authors(news_data)
            
            # íŠ¸ë Œë”© í† í”½ ë¶„ì„
            trending_topics = self.identify_trending_topics(news_data)
            
            conn.close()
            
            return {
                'keywords': keywords_analysis,
                'categories': categories_analysis,
                'authors': authors_analysis,
                'trending_topics': trending_topics,
                'total_articles': len(news_data)
            }
            
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {}
            
    def analyze_keywords_enhanced(self, news_data):
        """í–¥ìƒëœ í‚¤ì›Œë“œ ë¶„ì„"""
        # í™•ì¥ëœ í¬ì»¤ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        poker_keywords = [
            # í”Œë«í¼
            'PokerStars', 'GGPoker', 'GGNetwork', '888poker', 'partypoker', 
            'WPT Global', 'WPT', 'Winamax', 'Unibet', 'iPoker',
            
            # ì´ë²¤íŠ¸
            'WSOP', 'World Series', 'EPT', 'European Poker Tour', 
            'Main Event', 'bracelet', 'final table', 'heads-up',
            
            # ê²Œì„ íƒ€ì…
            'tournament', 'cash game', 'high stakes', 'sit and go',
            'spin and go', 'bounty', 'progressive knockout', 'PKO',
            
            # ì¼ë°˜
            'poker', 'player', 'champion', 'winner', 'prize pool',
            'buy-in', 'blinds', 'ante', 'all-in', 'bluff'
        ]
        
        keyword_counts = Counter()
        keyword_contexts = defaultdict(list)
        
        for row in news_data:
            title = row[0] or ''
            content = row[1] or ''
            text = (title + ' ' + content).lower()
            
            for keyword in poker_keywords:
                keyword_lower = keyword.lower()
                count = text.count(keyword_lower)
                if count > 0:
                    keyword_counts[keyword] += count
                    # í‚¤ì›Œë“œ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ì €ì¥
                    if keyword_lower in title.lower():
                        keyword_contexts[keyword].append(title[:100])
                        
        # ìƒìœ„ 15ê°œ í‚¤ì›Œë“œ
        top_keywords = dict(keyword_counts.most_common(15))
        
        # í‚¤ì›Œë“œë³„ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        keyword_details = {}
        for keyword, count in top_keywords.items():
            keyword_details[keyword] = {
                'count': count,
                'contexts': keyword_contexts[keyword][:3]  # ìƒìœ„ 3ê°œ ì»¨í…ìŠ¤íŠ¸
            }
            
        return keyword_details
        
    def analyze_categories_enhanced(self, news_data):
        """í–¥ìƒëœ ì¹´í…Œê³ ë¦¬ ë¶„ì„"""
        category_stats = defaultdict(int)
        category_trends = defaultdict(list)
        
        for row in news_data:
            category = row[2] or 'general'
            published_date = row[4] or datetime.now().strftime('%Y-%m-%d')
            
            category_stats[category] += 1
            category_trends[category].append(published_date)
            
        # ì¹´í…Œê³ ë¦¬ë³„ ìµœê·¼ í™œë™ë„ ê³„ì‚°
        category_analysis = {}
        for category, count in category_stats.items():
            recent_dates = category_trends[category]
            # ìµœê·¼ 7ì¼ ë‚´ ê¸°ì‚¬ ë¹„ìœ¨
            recent_articles = len([d for d in recent_dates if d >= (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')])
            recent_ratio = (recent_articles / count) * 100 if count > 0 else 0
            
            category_analysis[category] = {
                'total_articles': count,
                'recent_activity': round(recent_ratio, 1),
                'trend': 'hot' if recent_ratio > 50 else 'normal' if recent_ratio > 20 else 'cold'
            }
            
        return category_analysis
        
    def analyze_authors(self, news_data):
        """ì €ìë³„ ë¶„ì„"""
        author_stats = Counter()
        
        for row in news_data:
            author = row[3] or 'Unknown'
            # ì €ìëª… ì •ë¦¬ (ì²« ë²ˆì§¸ ì¤„ë§Œ)
            clean_author = author.split('\n')[0].strip() if author else 'Unknown'
            if clean_author and len(clean_author) < 50:  # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ ì œì™¸
                author_stats[clean_author] += 1
                
        # ìƒìœ„ 10ëª… ì €ì
        top_authors = dict(author_stats.most_common(10))
        
        return top_authors
        
    def identify_trending_topics(self, news_data):
        """íŠ¸ë Œë”© í† í”½ ì‹ë³„"""
        # ì œëª©ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ ì¡°í•© ì°¾ê¸°
        title_words = []
        
        for row in news_data:
            title = row[0] or ''
            # ì œëª©ì„ ë‹¨ì–´ë¡œ ë¶„ë¦¬í•˜ê³  ì •ë¦¬
            words = [word.strip('.,!?()[]{}').lower() for word in title.split() if len(word) > 3]
            # ì˜ë¯¸ì—†ëŠ” ë‹¨ì–´ ì œì™¸
            stop_words = {'the', 'and', 'for', 'with', 'from', 'this', 'that', 'they', 'have', 'been', 'will', 'were'}
            words = [word for word in words if word not in stop_words]
            title_words.extend(words)
            
        # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
        word_counts = Counter(title_words)
        trending_words = dict(word_counts.most_common(20))
        
        # ì—°ê´€ í‚¤ì›Œë“œ ê·¸ë£¹ ìƒì„±
        trending_groups = self.group_related_keywords(trending_words)
        
        return {
            'individual_words': trending_words,
            'topic_groups': trending_groups
        }
        
    def group_related_keywords(self, word_counts):
        """ì—°ê´€ í‚¤ì›Œë“œ ê·¸ë£¹í™”"""
        # í¬ì»¤ ê´€ë ¨ ì£¼ì œë³„ ê·¸ë£¹
        topic_groups = {
            'tournaments': ['tournament', 'wsop', 'bracelet', 'event', 'championship', 'series'],
            'players': ['player', 'winner', 'champion', 'professional', 'pro'],
            'platforms': ['pokerstars', 'ggpoker', 'online', 'platform', 'site'],
            'money': ['prize', 'million', 'dollar', 'money', 'pot', 'stakes'],
            'events': ['final', 'table', 'heads', 'victory', 'defeated', 'wins']
        }
        
        grouped_results = {}
        
        for group_name, keywords in topic_groups.items():
            group_score = 0
            group_words = []
            
            for word, count in word_counts.items():
                if any(keyword in word.lower() for keyword in keywords):
                    group_score += count
                    group_words.append(f"{word} ({count})")
                    
            if group_score > 0:
                grouped_results[group_name] = {
                    'total_mentions': group_score,
                    'keywords': group_words[:5]  # ìƒìœ„ 5ê°œë§Œ
                }
                
        return grouped_results
        
    def generate_broadcast_summary(self, market_data, news_data):
        """ë°©ì†¡ìš© ì¢…í•© ìš”ì•½ ìƒì„±"""
        logger.info("ğŸ“º ë°©ì†¡ìš© ì¢…í•© ìš”ì•½ ìƒì„±...")
        
        summary = {
            'headline_stats': [],
            'market_insights': [],
            'news_highlights': [],
            'trending_now': [],
            'quick_facts': []
        }
        
        # í—¤ë“œë¼ì¸ í†µê³„
        if market_data:
            total_players = market_data.get('total_players_online', 0)
            market_leader = market_data.get('market_leader', 'N/A')
            leader_share = market_data.get('market_leader_share', 0)
            
            summary['headline_stats'] = [
                f"ì „ ì„¸ê³„ ì˜¨ë¼ì¸ í¬ì»¤ í”Œë ˆì´ì–´: {total_players:,}ëª…",
                f"ì‹œì¥ ë¦¬ë”: {market_leader} ({leader_share}% ì ìœ )",
                f"í™œì„± í¬ì»¤ ì‚¬ì´íŠ¸: {market_data.get('active_sites_count', 0)}ê°œ"
            ]
            
        # ì‹œì¥ ì¸ì‚¬ì´íŠ¸
        if market_data and market_data.get('top_sites_data'):
            top_sites = market_data['top_sites_data'][:5]
            
            summary['market_insights'] = [
                f"TOP 5 ì‚¬ì´íŠ¸ í˜„í™©:",
                *[f"  {i+1}. {site['name']}: {site['players']:,}ëª…" for i, site in enumerate(top_sites)]
            ]
            
        # ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸
        if news_data and news_data.get('keywords'):
            top_keywords = list(news_data['keywords'].items())[:5]
            summary['news_highlights'] = [
                f"ìµœê·¼ í¬ì»¤ ë‰´ìŠ¤ ì£¼ìš” í‚¤ì›Œë“œ:",
                *[f"  â€¢ {keyword}: {data['count'] if isinstance(data, dict) else data}íšŒ ì–¸ê¸‰" 
                  for keyword, data in top_keywords]
            ]
            
        # í˜„ì¬ íŠ¸ë Œë”©
        if news_data and news_data.get('trending_topics'):
            trending = news_data['trending_topics'].get('topic_groups', {})
            if trending:
                summary['trending_now'] = [
                    "í˜„ì¬ íŠ¸ë Œë”© í† í”½:",
                    *[f"  ğŸ“ˆ {topic}: {data['total_mentions']}íšŒ ì–¸ê¸‰" 
                      for topic, data in list(trending.items())[:3]]
                ]
                
        # ë¹ ë¥¸ íŒ©íŠ¸
        if market_data:
            cash_ratio = market_data.get('cash_tournament_ratio', 0)
            top3_share = market_data.get('top3_market_share', 0)
            
            summary['quick_facts'] = [
                f"ìºì‹œê²Œì„ vs í† ë„ˆë¨¼íŠ¸ ë¹„ìœ¨: {cash_ratio:.1f}% vs {100-cash_ratio:.1f}%",
                f"ìƒìœ„ 3ê°œ ì‚¬ì´íŠ¸ ì‹œì¥ ì ìœ ìœ¨: {top3_share:.1f}%",
                f"ë¶„ì„ëœ ë‰´ìŠ¤ ê¸°ì‚¬: {news_data.get('total_articles', 0)}ê°œ" if news_data else "ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ"
            ]
            
        return summary
        
    def save_comprehensive_analysis(self, results):
        """ì¢…í•© ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        output = {
            'analysis_timestamp': datetime.now().isoformat(),
            'analysis_version': '2.0_enhanced',
            'data_source': 'poker_insight_database',
            'results': results
        }
        
        # ìƒì„¸ ê²°ê³¼ ì €ì¥
        with open('comprehensive_trend_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
            
        # ë°©ì†¡ìš© ìš”ì•½ ì €ì¥
        if 'broadcast_summary' in results:
            with open('broadcast_ready_summary.txt', 'w', encoding='utf-8') as f:
                summary = results['broadcast_summary']
                
                f.write("=== í¬ì»¤ ì‹œì¥ ë¸Œë¦¬í•‘ ===\n\n")
                
                for section, items in summary.items():
                    if items:
                        f.write(f"{section.replace('_', ' ').title()}:\n")
                        for item in items:
                            f.write(f"{item}\n")
                        f.write("\n")
                        
        logger.info("ğŸ’¾ ì¢…í•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ“Š í–¥ìƒëœ í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ ì‹œì‘")
    print("="*60)
    
    analyzer = EnhancedPokerTrendAnalyzer()
    
    try:
        # 1. í˜„ì¬ ì‹œì¥ ë°ì´í„° ë¶„ì„
        market_data = analyzer.analyze_current_market_data()
        
        # 2. ë‰´ìŠ¤ ë°ì´í„° ë¶„ì„
        news_data = analyzer.analyze_news_data()
        
        # 3. ë°©ì†¡ìš© ìš”ì•½ ìƒì„±
        broadcast_summary = analyzer.generate_broadcast_summary(market_data, news_data)
        
        # 4. ê²°ê³¼ ì¶œë ¥
        print("\nğŸ† ì‹œì¥ í˜„í™©:")
        if market_data:
            print(f"  ì´ í”Œë ˆì´ì–´: {market_data.get('total_players_online', 0):,}ëª…")
            print(f"  ì‹œì¥ ë¦¬ë”: {market_data.get('market_leader', 'N/A')}")
            print(f"  í™œì„± ì‚¬ì´íŠ¸: {market_data.get('active_sites_count', 0)}ê°œ")
            
        print("\nğŸ“° ë‰´ìŠ¤ ë¶„ì„:")
        if news_data:
            print(f"  ë¶„ì„ëœ ê¸°ì‚¬: {news_data.get('total_articles', 0)}ê°œ")
            if news_data.get('keywords'):
                top_keyword = list(news_data['keywords'].items())[0]
                print(f"  ìµœë‹¤ ì–¸ê¸‰ í‚¤ì›Œë“œ: {top_keyword[0]}")
                
        print("\nğŸ“º ë°©ì†¡ìš© ìš”ì•½:")
        for section, items in broadcast_summary.items():
            if items:
                print(f"  {section}:")
                for item in items[:2]:  # ê° ì„¹ì…˜ë³„ ìƒìœ„ 2ê°œë§Œ ì¶œë ¥
                    print(f"    {item}")
                    
        # 5. ê²°ê³¼ ì €ì¥
        comprehensive_results = {
            'market_analysis': market_data,
            'news_analysis': news_data,
            'broadcast_summary': broadcast_summary
        }
        
        analyzer.save_comprehensive_analysis(comprehensive_results)
        
        print(f"\nâœ… í–¥ìƒëœ íŠ¸ë Œë“œ ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“Š ìƒì„¸ ê²°ê³¼: comprehensive_trend_analysis.json")
        print(f"ğŸ“º ë°©ì†¡ìš© ìš”ì•½: broadcast_ready_summary.txt")
        
        return True
        
    except Exception as e:
        logger.error(f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print(f"\nğŸš€ íŠ¸ë Œë“œ ë¶„ì„ ì™„ë£Œ! ë‹¤ìŒ: ì¼ì¼ ë¦¬í¬íŠ¸ ìë™ ìƒì„± ë˜ëŠ” ëŒ€ì‹œë³´ë“œ êµ¬í˜„")
    else:
        print(f"\nğŸ’€ ë¶„ì„ ì‹¤íŒ¨ - ë¬¸ì œ í•´ê²° í•„ìš”")