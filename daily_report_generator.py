#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì¼ì¼ í¬ì»¤ ì‹œì¥ ë¦¬í¬íŠ¸ ìë™ ìƒì„±ê¸°
"""
import sys
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

import json
import logging
import sqlite3
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import statistics

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DailyReportGenerator:
    def __init__(self, db_path='poker_insight.db'):
        self.db_path = db_path
        
    def get_db_connection(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        return sqlite3.connect(self.db_path)
        
    def generate_daily_report(self):
        """ì¼ì¼ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        logger.info("ğŸ“‹ ì¼ì¼ í¬ì»¤ ì‹œì¥ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘...")
        
        report_data = {
            'report_date': datetime.now().strftime('%Y-%m-%d'),
            'report_time': datetime.now().strftime('%H:%M:%S'),
            'market_summary': self.get_market_summary(),
            'top_performers': self.get_top_performers(),
            'market_trends': self.get_market_trends(),
            'news_highlights': self.get_news_highlights(),
            'broadcast_segments': self.generate_broadcast_segments(),
            'key_metrics': self.calculate_key_metrics(),
            'alerts_and_changes': self.detect_significant_changes()
        }
        
        return report_data
        
    def get_market_summary(self):
        """ì‹œì¥ ì „ì²´ ìš”ì•½"""
        logger.info("  ğŸ“Š ì‹œì¥ ìš”ì•½ ë°ì´í„° ìˆ˜ì§‘...")
        
        try:
            conn = self.get_db_connection()
            cursor = conn.cursor()
            
            # ì „ì²´ ì‹œì¥ ë°ì´í„°
            query = """
            SELECT 
                COUNT(*) as total_sites,
                SUM(td.total_players) as total_players,
                SUM(td.cash_players) as total_cash,
                SUM(td.tournament_players) as total_tournaments,
                AVG(td.seven_day_average) as avg_7day
            FROM poker_sites ps
            JOIN traffic_data td ON ps.id = td.site_id
            WHERE td.total_players > 0
            """
            
            cursor.execute(query)
            result = cursor.fetchone()
            
            if result:
                total_sites, total_players, total_cash, total_tournaments, avg_7day = result
                
                summary = {
                    'total_active_sites': total_sites,
                    'total_players_online': total_players or 0,
                    'total_cash_players': total_cash or 0,
                    'total_tournament_players': total_tournaments or 0,
                    'average_7day_traffic': round(avg_7day or 0),
                    'cash_percentage': round((total_cash / total_players) * 100, 1) if total_players > 0 else 0,
                    'tournament_percentage': round((total_tournaments / total_players) * 100, 1) if total_players > 0 else 0
                }
            else:
                summary = {
                    'total_active_sites': 0,
                    'total_players_online': 0,
                    'total_cash_players': 0,
                    'total_tournament_players': 0,
                    'average_7day_traffic': 0,
                    'cash_percentage': 0,
                    'tournament_percentage': 0
                }
                
            conn.close()
            return summary
            
        except Exception as e:
            logger.error(f"ì‹œì¥ ìš”ì•½ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
            return {}
            
    def get_top_performers(self):
        """ìƒìœ„ ì„±ê³¼ ì‚¬ì´íŠ¸ë“¤"""
        logger.info("  ğŸ† ìƒìœ„ ì„±ê³¼ ì‚¬ì´íŠ¸ ë¶„ì„...")
        
        try:
            conn = self.get_db_connection()
            cursor = conn.cursor()
            
            query = """
            SELECT 
                ps.name,
                td.total_players,
                td.cash_players,
                td.tournament_players,
                td.seven_day_average,
                td.rank
            FROM poker_sites ps
            JOIN traffic_data td ON ps.id = td.site_id
            ORDER BY td.total_players DESC
            LIMIT 10
            """
            
            cursor.execute(query)
            results = cursor.fetchall()
            
            top_sites = []
            for row in results:
                name, total, cash, tournaments, avg_7day, rank = row
                
                # ì„±ì¥ë¥  ê³„ì‚° (7ì¼ í‰ê·  ëŒ€ë¹„ í˜„ì¬)
                growth_rate = 0
                if avg_7day and avg_7day > 0:
                    growth_rate = ((total - avg_7day) / avg_7day) * 100
                
                top_sites.append({
                    'name': name,
                    'rank': rank,
                    'total_players': total,
                    'cash_players': cash,
                    'tournament_players': tournaments,
                    'seven_day_average': avg_7day or 0,
                    'growth_rate': round(growth_rate, 1),
                    'market_share': 0  # ë‚˜ì¤‘ì— ê³„ì‚°
                })
                
            # ì‹œì¥ ì ìœ ìœ¨ ê³„ì‚°
            total_market = sum(site['total_players'] for site in top_sites)
            for site in top_sites:
                if total_market > 0:
                    site['market_share'] = round((site['total_players'] / total_market) * 100, 1)
                    
            conn.close()
            return top_sites
            
        except Exception as e:
            logger.error(f"ìƒìœ„ ì„±ê³¼ ì‚¬ì´íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return []
            
    def get_market_trends(self):
        """ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„"""
        logger.info("  ğŸ“ˆ ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„...")
        
        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” íˆìŠ¤í† ë¦¬ì»¬ ë°ì´í„°ë¥¼ ì‚¬ìš©
        # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ íŠ¸ë Œë“œ ìƒì„±
        trends = {
            'overall_trend': 'stable',  # 'growth', 'decline', 'stable'
            'growth_sites_count': 0,
            'decline_sites_count': 0,
            'stable_sites_count': 0,
            'biggest_gainer': {'name': '', 'growth': 0},
            'biggest_loser': {'name': '', 'decline': 0},
            'trend_analysis': []
        }
        
        try:
            top_sites = self.get_top_performers()
            
            growth_count = 0
            decline_count = 0
            stable_count = 0
            
            biggest_gainer = {'name': '', 'growth': 0}
            biggest_loser = {'name': '', 'decline': 0}
            
            for site in top_sites:
                growth_rate = site.get('growth_rate', 0)
                
                if growth_rate > 5:
                    growth_count += 1
                    if growth_rate > biggest_gainer['growth']:
                        biggest_gainer = {'name': site['name'], 'growth': growth_rate}
                elif growth_rate < -5:
                    decline_count += 1
                    if growth_rate < biggest_loser['decline']:
                        biggest_loser = {'name': site['name'], 'decline': growth_rate}
                else:
                    stable_count += 1
                    
            # ì „ì²´ íŠ¸ë Œë“œ ê²°ì •
            if growth_count > decline_count:
                overall_trend = 'growth'
            elif decline_count > growth_count:
                overall_trend = 'decline'
            else:
                overall_trend = 'stable'
                
            trends.update({
                'overall_trend': overall_trend,
                'growth_sites_count': growth_count,
                'decline_sites_count': decline_count,
                'stable_sites_count': stable_count,
                'biggest_gainer': biggest_gainer,
                'biggest_loser': biggest_loser
            })
            
            return trends
            
        except Exception as e:
            logger.error(f"ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return trends
            
    def get_news_highlights(self):
        """ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸"""
        logger.info("  ğŸ“° ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸ ìˆ˜ì§‘...")
        
        try:
            conn = self.get_db_connection()
            cursor = conn.cursor()
            
            # ìµœì‹  ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            query = """
            SELECT title, content, category, author, published_date, url
            FROM news_items
            ORDER BY scraped_at DESC
            LIMIT 20
            """
            
            cursor.execute(query)
            news_data = cursor.fetchall()
            
            # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
            category_stats = Counter()
            top_keywords = Counter()
            featured_news = []
            
            # ì¤‘ìš” í‚¤ì›Œë“œ ì •ì˜
            important_keywords = ['WSOP', 'PokerStars', 'GGPoker', 'tournament', 'bracelet', 'winner', 'champion']
            
            for row in news_data:
                title, content, category, author, pub_date, url = row
                
                category_stats[category or 'general'] += 1
                
                # í‚¤ì›Œë“œ ë¶„ì„
                text = (title + ' ' + (content or '')).lower()
                for keyword in important_keywords:
                    if keyword.lower() in text:
                        top_keywords[keyword] += 1
                        
                # ì¤‘ìš” ë‰´ìŠ¤ ì„ ë³„ (ì œëª©ì— ì¤‘ìš” í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°)
                if any(keyword.lower() in title.lower() for keyword in important_keywords[:5]):
                    featured_news.append({
                        'title': title,
                        'category': category,
                        'author': author,
                        'published_date': pub_date,
                        'url': url,
                        'importance': 'high'
                    })
                    
            conn.close()
            
            return {
                'total_articles': len(news_data),
                'category_breakdown': dict(category_stats.most_common(5)),
                'trending_keywords': dict(top_keywords.most_common(10)),
                'featured_articles': featured_news[:5],
                'news_sentiment': self.analyze_news_sentiment(news_data)
            }
            
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸ ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
            return {}
            
    def analyze_news_sentiment(self, news_data):
        """ë‰´ìŠ¤ ê°ì • ë¶„ì„"""
        positive_words = ['win', 'winner', 'champion', 'success', 'record', 'best', 'great', 'amazing', 'victory']
        negative_words = ['lose', 'lost', 'fail', 'worst', 'bad', 'terrible', 'scandal', 'controversy', 'defeat']
        
        positive_count = 0
        negative_count = 0
        
        for row in news_data:
            title = row[0] or ''
            content = row[1] or ''
            text = (title + ' ' + content).lower()
            
            pos_score = sum(text.count(word) for word in positive_words)
            neg_score = sum(text.count(word) for word in negative_words)
            
            if pos_score > neg_score:
                positive_count += 1
            elif neg_score > pos_score:
                negative_count += 1
                
        total = len(news_data)
        if total > 0:
            return {
                'positive_ratio': round((positive_count / total) * 100, 1),
                'negative_ratio': round((negative_count / total) * 100, 1),
                'neutral_ratio': round(((total - positive_count - negative_count) / total) * 100, 1),
                'overall_sentiment': 'positive' if positive_count > negative_count else 'negative' if negative_count > positive_count else 'neutral'
            }
        return {'positive_ratio': 0, 'negative_ratio': 0, 'neutral_ratio': 100, 'overall_sentiment': 'neutral'}
        
    def generate_broadcast_segments(self):
        """ë°©ì†¡ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±"""
        logger.info("  ğŸ“º ë°©ì†¡ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±...")
        
        market_summary = self.get_market_summary()
        top_performers = self.get_top_performers()
        market_trends = self.get_market_trends()
        news_highlights = self.get_news_highlights()
        
        segments = {
            'opening_segment': self.create_opening_segment(market_summary, top_performers),
            'market_analysis': self.create_market_analysis_segment(market_trends, top_performers),
            'news_segment': self.create_news_segment(news_highlights),
            'closing_segment': self.create_closing_segment(market_trends)
        }
        
        return segments
        
    def create_opening_segment(self, market_summary, top_performers):
        """ì˜¤í”„ë‹ ì„¸ê·¸ë¨¼íŠ¸"""
        total_players = market_summary.get('total_players_online', 0)
        leader = top_performers[0] if top_performers else {'name': 'N/A', 'total_players': 0}
        
        segment = {
            'headline': f"ì˜¤ëŠ˜ì˜ ì˜¨ë¼ì¸ í¬ì»¤ ì‹œì¥ í˜„í™©",
            'key_stats': [
                f"ì „ ì„¸ê³„ ì˜¨ë¼ì¸ í¬ì»¤ í”Œë ˆì´ì–´: {total_players:,}ëª…",
                f"ì‹œì¥ ë¦¬ë”: {leader['name']} ({leader['total_players']:,}ëª…)",
                f"í™œì„± í¬ì»¤ ì‚¬ì´íŠ¸: {market_summary.get('total_active_sites', 0)}ê°œ"
            ],
            'talking_points': [
                f"í˜„ì¬ ì˜¨ë¼ì¸ í¬ì»¤ ì‹œì¥ì—ëŠ” ì´ {total_players:,}ëª…ì˜ í”Œë ˆì´ì–´ê°€ í™œë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                f"{leader['name']}ì´ {leader['total_players']:,}ëª…ìœ¼ë¡œ ì‹œì¥ì„ ì„ ë„í•˜ê³  ìˆìŠµë‹ˆë‹¤."
            ]
        }
        
        return segment
        
    def create_market_analysis_segment(self, market_trends, top_performers):
        """ì‹œì¥ ë¶„ì„ ì„¸ê·¸ë¨¼íŠ¸"""
        trend = market_trends.get('overall_trend', 'stable')
        trend_desc = {
            'growth': 'ì„±ì¥ì„¸',
            'decline': 'í•˜ë½ì„¸',
            'stable': 'ì•ˆì •ì„¸'
        }.get(trend, 'ì•ˆì •ì„¸')
        
        biggest_gainer = market_trends.get('biggest_gainer', {})
        top_3_sites = top_performers[:3] if len(top_performers) >= 3 else top_performers
        
        segment = {
            'headline': f"ì‹œì¥ ë¶„ì„: ì „ì²´ì ìœ¼ë¡œ {trend_desc}ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤",
            'market_overview': [
                f"ì„±ì¥ ì‚¬ì´íŠ¸: {market_trends.get('growth_sites_count', 0)}ê°œ",
                f"í•˜ë½ ì‚¬ì´íŠ¸: {market_trends.get('decline_sites_count', 0)}ê°œ",
                f"ì•ˆì • ì‚¬ì´íŠ¸: {market_trends.get('stable_sites_count', 0)}ê°œ"
            ],
            'top_3_breakdown': [
                f"{i+1}ìœ„. {site['name']}: {site['total_players']:,}ëª… ({site['market_share']}%)"
                for i, site in enumerate(top_3_sites)
            ],
            'highlight': biggest_gainer.get('name', '') and f"ê°€ì¥ ì£¼ëª©í•  ë§Œí•œ ì„±ì¥ì„ ë³´ì¸ ì‚¬ì´íŠ¸ëŠ” {biggest_gainer['name']}ë¡œ {biggest_gainer['growth']:+.1f}% ì¦ê°€í–ˆìŠµë‹ˆë‹¤." or ""
        }
        
        return segment
        
    def create_news_segment(self, news_highlights):
        """ë‰´ìŠ¤ ì„¸ê·¸ë¨¼íŠ¸"""
        trending_keywords = news_highlights.get('trending_keywords', {})
        featured_articles = news_highlights.get('featured_articles', [])
        sentiment = news_highlights.get('news_sentiment', {})
        
        top_keyword = max(trending_keywords.items(), key=lambda x: x[1]) if trending_keywords else ('', 0)
        
        segment = {
            'headline': "í¬ì»¤ ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸",
            'news_overview': [
                f"ë¶„ì„ëœ ê¸°ì‚¬: {news_highlights.get('total_articles', 0)}ê°œ",
                f"ì „ì²´ ë‰´ìŠ¤ í†¤: {sentiment.get('overall_sentiment', 'neutral')}",
                f"ê°€ì¥ í•«í•œ í‚¤ì›Œë“œ: {top_keyword[0]} ({top_keyword[1]}íšŒ ì–¸ê¸‰)" if top_keyword[0] else "í‚¤ì›Œë“œ ë¶„ì„ ë°ì´í„° ì—†ìŒ"
            ],
            'featured_stories': [
                {
                    'title': article['title'],
                    'category': article['category'],
                    'talking_point': f"{article['category']} ì¹´í…Œê³ ë¦¬ì˜ ì£¼ìš” ì†Œì‹ì…ë‹ˆë‹¤."
                }
                for article in featured_articles[:3]
            ],
            'trending_topics': list(trending_keywords.keys())[:5]
        }
        
        return segment
        
    def create_closing_segment(self, market_trends):
        """í´ë¡œì§• ì„¸ê·¸ë¨¼íŠ¸"""
        trend = market_trends.get('overall_trend', 'stable')
        
        outlook = {
            'growth': "ì•ìœ¼ë¡œë„ ì„±ì¥ì„¸ê°€ ì§€ì†ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.",
            'decline': "ì‹œì¥ íšŒë³µì„ ìœ„í•œ ê´€ì°°ì´ í•„ìš”í•œ ìƒí™©ì…ë‹ˆë‹¤.",
            'stable': "ì•ˆì •ì ì¸ ì‹œì¥ ìƒí™©ì´ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤."
        }.get(trend, "ì‹œì¥ ìƒí™©ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê² ìŠµë‹ˆë‹¤.")
        
        segment = {
            'headline': "ì˜¤ëŠ˜ì˜ í¬ì»¤ ì‹œì¥ ì´í‰",
            'summary_points': [
                f"ì „ì²´ ì‹œì¥ì€ {trend}í•œ ëª¨ìŠµì„ ë³´ì˜€ìŠµë‹ˆë‹¤.",
                f"ìƒìœ„ ì‚¬ì´íŠ¸ë“¤ì˜ ê²½ìŸì´ ê³„ì†ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
                "í¬ì»¤ ë‰´ìŠ¤ì—ì„œëŠ” ë‹¤ì–‘í•œ í† ë„ˆë¨¼íŠ¸ ì†Œì‹ì´ ì£¼ë¥¼ ì´ë¤˜ìŠµë‹ˆë‹¤."
            ],
            'outlook': outlook,
            'next_watch': "ë‚´ì¼ì€ ì–´ë–¤ ë³€í™”ê°€ ìˆì„ì§€ ì§€ì¼œë³´ê² ìŠµë‹ˆë‹¤."
        }
        
        return segment
        
    def calculate_key_metrics(self):
        """í•µì‹¬ ì§€í‘œ ê³„ì‚°"""
        logger.info("  ğŸ“Š í•µì‹¬ ì§€í‘œ ê³„ì‚°...")
        
        market_summary = self.get_market_summary()
        top_performers = self.get_top_performers()
        
        # HHI (í—ˆí•€ë‹¬-í—ˆì‹œë§Œ ì§€ìˆ˜) - ì‹œì¥ ì§‘ì¤‘ë„
        hhi = 0
        total_players = market_summary.get('total_players_online', 0)
        
        if total_players > 0:
            for site in top_performers:
                market_share = (site['total_players'] / total_players) * 100
                hhi += market_share ** 2
                
        # ìƒìœ„ 3ê°œ ì‚¬ì´íŠ¸ ì§‘ì¤‘ë„
        top3_concentration = sum(site['market_share'] for site in top_performers[:3])
        
        metrics = {
            'market_concentration_hhi': round(hhi, 2),
            'top3_concentration': round(top3_concentration, 1),
            'average_site_size': round(total_players / len(top_performers), 0) if top_performers else 0,
            'cash_vs_tournament_ratio': f"{market_summary.get('cash_percentage', 0):.1f}% : {market_summary.get('tournament_percentage', 0):.1f}%",
            'market_diversity': 'high' if hhi < 1500 else 'medium' if hhi < 2500 else 'low'
        }
        
        return metrics
        
    def detect_significant_changes(self):
        """ì¤‘ìš”í•œ ë³€í™” ê°ì§€"""
        logger.info("  ğŸš¨ ì¤‘ìš”í•œ ë³€í™” ê°ì§€...")
        
        alerts = []
        
        try:
            top_performers = self.get_top_performers()
            
            for site in top_performers:
                growth_rate = site.get('growth_rate', 0)
                
                # ê¸‰ê²©í•œ ë³€í™” ê°ì§€
                if abs(growth_rate) > 20:
                    severity = 'high'
                    alert_type = 'ê¸‰ë“±' if growth_rate > 0 else 'ê¸‰ë½'
                elif abs(growth_rate) > 10:
                    severity = 'medium'
                    alert_type = 'ìƒìŠ¹' if growth_rate > 0 else 'í•˜ë½'
                else:
                    continue
                    
                alerts.append({
                    'site': site['name'],
                    'type': alert_type,
                    'change': f"{growth_rate:+.1f}%",
                    'severity': severity,
                    'current_players': site['total_players'],
                    'description': f"{site['name']}ì—ì„œ {alert_type} ({growth_rate:+.1f}%) ê°ì§€"
                })
                
            # ì‹¬ê°ë„ìˆœìœ¼ë¡œ ì •ë ¬
            alerts.sort(key=lambda x: (x['severity'] == 'high', abs(float(x['change'].replace('%', '').replace('+', '')))), reverse=True)
            
            return alerts[:5]  # ìƒìœ„ 5ê°œë§Œ
            
        except Exception as e:
            logger.error(f"ë³€í™” ê°ì§€ ì˜¤ë¥˜: {str(e)}")
            return []
            
    def save_daily_report(self, report_data):
        """ì¼ì¼ ë¦¬í¬íŠ¸ ì €ì¥"""
        logger.info("ğŸ’¾ ì¼ì¼ ë¦¬í¬íŠ¸ ì €ì¥...")
        
        # JSON í˜•íƒœë¡œ ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        json_filename = f'daily_report_{timestamp}.json'
        
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
            
        # ë°©ì†¡ìš© ê°„ë‹¨ ë¦¬í¬íŠ¸ ì €ì¥
        text_filename = f'broadcast_report_{timestamp}.txt'
        self.save_broadcast_report(report_data, text_filename)
        
        logger.info(f"ğŸ“Š ìƒì„¸ ë¦¬í¬íŠ¸: {json_filename}")
        logger.info(f"ğŸ“º ë°©ì†¡ìš© ë¦¬í¬íŠ¸: {text_filename}")
        
        return json_filename, text_filename
        
    def save_broadcast_report(self, report_data, filename):
        """ë°©ì†¡ìš© ê°„ë‹¨ ë¦¬í¬íŠ¸ ì €ì¥"""
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write(f"ì¼ì¼ í¬ì»¤ ì‹œì¥ ë¸Œë¦¬í•‘ - {report_data['report_date']}\n")
            f.write("=" * 60 + "\n\n")
            
            # ì˜¤í”„ë‹ ì„¸ê·¸ë¨¼íŠ¸
            opening = report_data['broadcast_segments']['opening_segment']
            f.write("ğŸ“º ì˜¤í”„ë‹ ì„¸ê·¸ë¨¼íŠ¸\n")
            f.write("-" * 30 + "\n")
            f.write(f"í—¤ë“œë¼ì¸: {opening['headline']}\n\n")
            f.write("ì£¼ìš” í†µê³„:\n")
            for stat in opening['key_stats']:
                f.write(f"  â€¢ {stat}\n")
            f.write("\në°©ì†¡ ë©˜íŠ¸:\n")
            for point in opening['talking_points']:
                f.write(f"  \"{point}\"\n")
            f.write("\n")
            
            # ì‹œì¥ ë¶„ì„ ì„¸ê·¸ë¨¼íŠ¸
            market = report_data['broadcast_segments']['market_analysis']
            f.write("ğŸ“Š ì‹œì¥ ë¶„ì„ ì„¸ê·¸ë¨¼íŠ¸\n")
            f.write("-" * 30 + "\n")
            f.write(f"í—¤ë“œë¼ì¸: {market['headline']}\n\n")
            f.write("TOP 3 ì‚¬ì´íŠ¸:\n")
            for breakdown in market['top_3_breakdown']:
                f.write(f"  â€¢ {breakdown}\n")
            if market['highlight']:
                f.write(f"\níŠ¹ë³„ ì–¸ê¸‰: {market['highlight']}\n")
            f.write("\n")
            
            # ë‰´ìŠ¤ ì„¸ê·¸ë¨¼íŠ¸
            news = report_data['broadcast_segments']['news_segment']
            f.write("ğŸ“° ë‰´ìŠ¤ ì„¸ê·¸ë¨¼íŠ¸\n")
            f.write("-" * 30 + "\n")
            f.write("ë‰´ìŠ¤ ê°œìš”:\n")
            for overview in news['news_overview']:
                f.write(f"  â€¢ {overview}\n")
            f.write("\nì£¼ìš” ê¸°ì‚¬:\n")
            for story in news['featured_stories']:
                f.write(f"  â€¢ {story['title']}\n")
            f.write("\n")
            
            # í´ë¡œì§• ì„¸ê·¸ë¨¼íŠ¸
            closing = report_data['broadcast_segments']['closing_segment']
            f.write("ğŸ¬ í´ë¡œì§• ì„¸ê·¸ë¨¼íŠ¸\n")
            f.write("-" * 30 + "\n")
            f.write(f"í—¤ë“œë¼ì¸: {closing['headline']}\n\n")
            f.write("ì´í‰:\n")
            for summary in closing['summary_points']:
                f.write(f"  â€¢ {summary}\n")
            f.write(f"\nì „ë§: {closing['outlook']}\n")
            f.write(f"ë§ˆë¬´ë¦¬: {closing['next_watch']}\n")
            f.write("\n")
            
            # ì•Œë¦¼ ì‚¬í•­
            if report_data['alerts_and_changes']:
                f.write("ğŸš¨ ì£¼ìš” ë³€í™” ì•Œë¦¼\n")
                f.write("-" * 30 + "\n")
                for alert in report_data['alerts_and_changes']:
                    f.write(f"  â€¢ {alert['description']}\n")
                f.write("\n")
                
            f.write("=" * 60 + "\n")
            f.write("ë¦¬í¬íŠ¸ ìƒì„± ì‹œê°„: " + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + "\n")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ“‹ ì¼ì¼ í¬ì»¤ ì‹œì¥ ë¦¬í¬íŠ¸ ìƒì„±ê¸°")
    print("=" * 50)
    
    generator = DailyReportGenerator()
    
    try:
        # ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„±
        print("\nğŸ”„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        report_data = generator.generate_daily_report()
        
        # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
        print("\nğŸ“Š ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸°:")
        market_summary = report_data.get('market_summary', {})
        print(f"  ì´ í”Œë ˆì´ì–´: {market_summary.get('total_players_online', 0):,}ëª…")
        print(f"  í™œì„± ì‚¬ì´íŠ¸: {market_summary.get('total_active_sites', 0)}ê°œ")
        
        top_performers = report_data.get('top_performers', [])
        if top_performers:
            print(f"  ì‹œì¥ ë¦¬ë”: {top_performers[0]['name']} ({top_performers[0]['total_players']:,}ëª…)")
            
        news_highlights = report_data.get('news_highlights', {})
        print(f"  ë¶„ì„ëœ ë‰´ìŠ¤: {news_highlights.get('total_articles', 0)}ê°œ")
        
        alerts = report_data.get('alerts_and_changes', [])
        if alerts:
            print(f"  ì¤‘ìš” ì•Œë¦¼: {len(alerts)}ê±´")
            for alert in alerts[:2]:
                print(f"    - {alert['description']}")
                
        # ë¦¬í¬íŠ¸ ì €ì¥
        print("\nğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥ ì¤‘...")
        json_file, text_file = generator.save_daily_report(report_data)
        
        print(f"\nâœ… ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“Š ìƒì„¸ ë¶„ì„: {json_file}")
        print(f"ğŸ“º ë°©ì†¡ìš© ìŠ¤í¬ë¦½íŠ¸: {text_file}")
        
        return True
        
    except Exception as e:
        logger.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print(f"\nğŸš€ ì¼ì¼ ë¦¬í¬íŠ¸ ì™„ë£Œ! ë‹¤ìŒ: ê¸°ë³¸ ëŒ€ì‹œë³´ë“œ êµ¬í˜„")
    else:
        print(f"\nğŸ’€ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨ - ë¬¸ì œ í•´ê²° í•„ìš”")