#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìš´ì˜ìš© í¬ì»¤ ì‚¬ì´íŠ¸ ë°ì´í„° ìˆ˜ì§‘ê¸°
- GG POKER ë°ì´í„° í¬í•¨ í¬ë¡¤ë§
- 4ê°œ í•µì‹¬ ì§€í‘œ ìë™ ìˆ˜ì§‘
- í•œ ë‹¬ê°„ ì¼ì¼ ë°ì´í„° ì¶•ì 
- CloudScraperë¥¼ í†µí•œ ì•ˆì •ì  ìˆ˜ì§‘
"""
import sys
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

import os
import time
import logging
import sqlite3
from datetime import datetime, timedelta
import cloudscraper
from bs4 import BeautifulSoup
import re
import json
from gg_poker_monitoring import GGPokerMonitoringPlatform

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('poker_data_collection.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class ProductionDataCollector:
    def __init__(self, db_path='gg_poker_monitoring.db'):
        self.db_path = db_path
        self.scraper = cloudscraper.create_scraper(
            browser={'browser': 'chrome', 'platform': 'windows', 'mobile': False}
        )
        self.monitoring_platform = GGPokerMonitoringPlatform(db_path)
        self.setup_target_sites()
        
    def setup_target_sites(self):
        """ìˆ˜ì§‘ ëŒ€ìƒ ì‚¬ì´íŠ¸ ì„¤ì • (GG POKER í¬í•¨)"""
        self.target_sites = {
            # GG POKER ë„¤íŠ¸ì›Œí¬ (ìµœê³  ìš°ì„ ìˆœìœ„)
            'GGNetwork': {
                'priority': 1,
                'category': 'GG_POKER',
                'expected_players': 130000
            },
            'GGPoker ON': {
                'priority': 1, 
                'category': 'GG_POKER',
                'expected_players': 5000
            },
            
            # Tier 1 ì§ì ‘ ê²½ìŸì‚¬
            'PokerStars': {
                'priority': 2,
                'category': 'DIRECT_COMPETITOR',
                'expected_players': 55000
            },
            'PokerStars Ontario': {
                'priority': 2,
                'category': 'DIRECT_COMPETITOR', 
                'expected_players': 55000
            },
            
            # Tier 2 ì£¼ìš” ê²½ìŸì‚¬
            'WPT Global': {
                'priority': 3,
                'category': 'MAJOR_COMPETITOR',
                'expected_players': 3000
            },
            '888poker': {
                'priority': 3,
                'category': 'MAJOR_COMPETITOR',
                'expected_players': 2000
            },
            'partypoker': {
                'priority': 3,
                'category': 'MAJOR_COMPETITOR',
                'expected_players': 1500
            },
            
            # Tier 3 ê¸°íƒ€ ê²½ìŸì‚¬
            'Chico Poker': {
                'priority': 4,
                'category': 'OTHER_COMPETITOR',
                'expected_players': 2000
            },
            'iPoker': {
                'priority': 4,
                'category': 'OTHER_COMPETITOR',
                'expected_players': 1000
            },
            'Winamax': {
                'priority': 4,
                'category': 'OTHER_COMPETITOR',
                'expected_players': 800
            }
        }
        
        logger.info(f"ğŸ“‹ ìˆ˜ì§‘ ëŒ€ìƒ ì‚¬ì´íŠ¸ ì„¤ì • ì™„ë£Œ: {len(self.target_sites)}ê°œ")
        
    def crawl_pokerscout_data(self):
        """PokerScoutì—ì„œ ì‹¤ì‹œê°„ ë°ì´í„° í¬ë¡¤ë§"""
        logger.info("ğŸ” PokerScout ë°ì´í„° í¬ë¡¤ë§ ì‹œì‘...")
        
        try:
            # PokerScout ë©”ì¸ í˜ì´ì§€ í¬ë¡¤ë§
            response = self.scraper.get('https://www.pokerscout.com', timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ë­í‚¹ í…Œì´ë¸” ì°¾ê¸°
            table = soup.find('table', {'class': 'rankTable'})
            if not table:
                logger.error("âŒ PokerScout ë­í‚¹ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            collected_data = []
            rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸
            
            for row in rows:
                try:
                    cells = row.find_all('td')
                    if len(cells) < 6:
                        continue
                    
                    # ì‚¬ì´íŠ¸ëª… ì¶”ì¶œ
                    site_name_cell = cells[1]
                    site_name = site_name_cell.get_text(strip=True)
                    
                    # ì •í™•í•œ ì‚¬ì´íŠ¸ëª… ë§¤ì¹­
                    normalized_site = self.normalize_site_name(site_name)
                    if normalized_site not in self.target_sites:
                        continue
                    
                    # í”Œë ˆì´ì–´ ìˆ˜ ì¶”ì¶œ
                    players_text = cells[2].get_text(strip=True).replace(',', '')
                    players_online = int(re.sub(r'[^\d]', '', players_text)) if players_text.isdigit() else 0
                    
                    # ìºì‹œ í”Œë ˆì´ì–´ ì¶”ì¶œ
                    cash_text = cells[3].get_text(strip=True).replace(',', '')
                    cash_players = int(re.sub(r'[^\d]', '', cash_text)) if cash_text.isdigit() else 0
                    
                    # 24ì‹œê°„ í”¼í¬ ì¶”ì¶œ
                    peak_text = cells[4].get_text(strip=True).replace(',', '')
                    peak_24h = int(re.sub(r'[^\d]', '', peak_text)) if peak_text.isdigit() else 0
                    
                    # 7ì¼ í‰ê·  ì¶”ì¶œ
                    avg_text = cells[5].get_text(strip=True).replace(',', '')
                    seven_day_avg = int(re.sub(r'[^\d]', '', avg_text)) if avg_text.isdigit() else 0
                    
                    site_data = {
                        'site_name': normalized_site,
                        'players_online': players_online,
                        'cash_players': cash_players,
                        'peak_24h': peak_24h,
                        'seven_day_avg': seven_day_avg,
                        'collection_time': datetime.now().isoformat(),
                        'source': 'PokerScout'
                    }
                    
                    collected_data.append(site_data)
                    
                    logger.info(f"âœ… {normalized_site}: {players_online:,}ëª… (ìºì‹œ: {cash_players:,}ëª…)")
                    
                except Exception as e:
                    logger.error(f"âŒ í–‰ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                    continue
            
            logger.info(f"ğŸ¯ PokerScout í¬ë¡¤ë§ ì™„ë£Œ: {len(collected_data)}ê°œ ì‚¬ì´íŠ¸")
            return collected_data
            
        except Exception as e:
            logger.error(f"âŒ PokerScout í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def normalize_site_name(self, raw_name):
        """ì‚¬ì´íŠ¸ëª… ì •ê·œí™”"""
        name_mapping = {
            'ggnetwork': 'GGNetwork',
            'gg network': 'GGNetwork', 
            'ggpoker': 'GGNetwork',
            'gg poker': 'GGNetwork',
            'ggpoker on': 'GGPoker ON',
            'pokerstars': 'PokerStars',
            'pokerstars ontario': 'PokerStars Ontario',
            'pokerstars.it': 'PokerStars.it',
            'wpt global': 'WPT Global',
            'worldpokertour': 'WPT Global',
            '888poker': '888poker',
            '888 poker': '888poker',
            'partypoker': 'partypoker',
            'party poker': 'partypoker',
            'chico poker': 'Chico Poker',
            'chico': 'Chico Poker',
            'ipoker': 'iPoker',
            'winamax': 'Winamax'
        }
        
        normalized = raw_name.lower().strip()
        return name_mapping.get(normalized, raw_name)
    
    def validate_data_quality(self, data):
        """ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
        validated_data = []
        
        for site_data in data:
            site_name = site_data['site_name']
            players = site_data['players_online']
            
            # ì˜ˆìƒ í”Œë ˆì´ì–´ ìˆ˜ì™€ ë¹„êµí•˜ì—¬ ì´ìƒì¹˜ ê²€ì¦
            expected = self.target_sites.get(site_name, {}).get('expected_players', 0)
            
            # ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ì€ ê°’ í•„í„°ë§
            if expected > 0:
                ratio = players / expected if expected > 0 else 0
                if ratio > 10 or ratio < 0.01:  # 10ë°° ì´ˆê³¼ ë˜ëŠ” 1% ë¯¸ë§Œ
                    logger.warning(f"âš ï¸ {site_name} ì´ìƒì¹˜ ê°ì§€: {players:,}ëª… (ì˜ˆìƒ: {expected:,}ëª…)")
                    continue
            
            # ê¸°ë³¸ì ì¸ ë²”ìœ„ ê²€ì¦
            if players < 0 or players > 500000:  # ìŒìˆ˜ì´ê±°ë‚˜ 50ë§Œ ì´ˆê³¼
                logger.warning(f"âš ï¸ {site_name} ë²”ìœ„ ì´ˆê³¼: {players:,}ëª…")
                continue
            
            # ìºì‹œ í”Œë ˆì´ì–´ê°€ ì´ í”Œë ˆì´ì–´ë³´ë‹¤ ë§ì€ ê²½ìš°
            if site_data['cash_players'] > players:
                logger.warning(f"âš ï¸ {site_name} ìºì‹œ í”Œë ˆì´ì–´ ìˆ˜ ì´ìƒ: {site_data['cash_players']:,} > {players:,}")
                site_data['cash_players'] = players  # ìˆ˜ì •
            
            validated_data.append(site_data)
        
        logger.info(f"âœ… ë°ì´í„° ê²€ì¦ ì™„ë£Œ: {len(validated_data)}/{len(data)}ê°œ ìœ íš¨")
        return validated_data
    
    def save_daily_data(self, data):
        """ì¼ì¼ ë°ì´í„° ì €ì¥"""
        if not data:
            logger.error("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        try:
            collected_count = self.monitoring_platform.collect_daily_data(data)
            
            # ìˆ˜ì§‘ í†µê³„ ë¡œê¹…
            collection_stats = {
                'collection_date': datetime.now().strftime('%Y-%m-%d'),
                'collection_time': datetime.now().strftime('%H:%M:%S'),
                'total_sites_collected': collected_count,
                'gg_poker_sites': len([d for d in data if 'GG' in d['site_name']]),
                'total_players': sum(d['players_online'] for d in data),
                'total_cash_players': sum(d['cash_players'] for d in data)
            }
            
            logger.info(f"ğŸ’¾ ì¼ì¼ ë°ì´í„° ì €ì¥ ì™„ë£Œ:")
            logger.info(f"  ğŸ“Š ìˆ˜ì§‘ ì‚¬ì´íŠ¸: {collection_stats['total_sites_collected']}ê°œ")
            logger.info(f"  ğŸ¯ GG POKER: {collection_stats['gg_poker_sites']}ê°œ ì‚¬ì´íŠ¸")
            logger.info(f"  ğŸ‘¥ ì´ í”Œë ˆì´ì–´: {collection_stats['total_players']:,}ëª…")
            logger.info(f"  ğŸ’° ìºì‹œ í”Œë ˆì´ì–´: {collection_stats['total_cash_players']:,}ëª…")
            
            # ìˆ˜ì§‘ í†µê³„ ì €ì¥
            self.save_collection_stats(collection_stats)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def save_collection_stats(self, stats):
        """ìˆ˜ì§‘ í†µê³„ ì €ì¥"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ìˆ˜ì§‘ í†µê³„ í…Œì´ë¸” ìƒì„±
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS collection_stats (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                collection_date DATE NOT NULL,
                collection_time TIME NOT NULL,
                total_sites_collected INTEGER,
                gg_poker_sites INTEGER,
                total_players INTEGER,
                total_cash_players INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            INSERT INTO collection_stats 
            (collection_date, collection_time, total_sites_collected, gg_poker_sites,
             total_players, total_cash_players)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            stats['collection_date'],
            stats['collection_time'],
            stats['total_sites_collected'],
            stats['gg_poker_sites'],
            stats['total_players'],
            stats['total_cash_players']
        ))
        
        conn.commit()
        conn.close()
    
    def run_daily_collection(self):
        """ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰"""
        start_time = datetime.now()
        logger.info(f"ğŸš€ ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # 1. PokerScout í¬ë¡¤ë§
            raw_data = self.crawl_pokerscout_data()
            
            if not raw_data:
                logger.error("âŒ í¬ë¡¤ë§ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            # 2. ë°ì´í„° ê²€ì¦
            validated_data = self.validate_data_quality(raw_data)
            
            # 3. ë°ì´í„° ì €ì¥
            success = self.save_daily_data(validated_data)
            
            # 4. ë³€í™” ê°ì§€ (ì „ì¼ ëŒ€ë¹„)
            if success:
                changes = self.monitoring_platform.detect_significant_changes()
                if changes:
                    logger.info(f"ğŸš¨ ìœ ì˜ë¯¸í•œ ë³€í™” ê°ì§€: {len(changes)}ê±´")
                    for change in changes[:3]:  # ìƒìœ„ 3ê°œë§Œ ë¡œê¹…
                        logger.info(f"  ğŸ“ˆ {change['site_name']}: {change['metric']} {change['change_percentage']:+.1f}%")
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            logger.info(f"âœ… ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {duration:.1f}ì´ˆ)")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def get_collection_summary(self, days_back=7):
        """ìˆ˜ì§‘ í˜„í™© ìš”ì•½"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ìµœê·¼ ìˆ˜ì§‘ í†µê³„
        cursor.execute('''
            SELECT 
                collection_date,
                total_sites_collected,
                gg_poker_sites,
                total_players,
                total_cash_players
            FROM collection_stats 
            WHERE collection_date >= date('now', '-' || ? || ' days')
            ORDER BY collection_date DESC
        ''', (days_back,))
        
        recent_stats = cursor.fetchall()
        
        # ì „ì²´ ìˆ˜ì§‘ í˜„í™©
        cursor.execute('''
            SELECT 
                COUNT(DISTINCT collection_date) as total_days,
                AVG(total_sites_collected) as avg_sites,
                AVG(total_players) as avg_players,
                MIN(collection_date) as first_collection,
                MAX(collection_date) as last_collection
            FROM collection_stats
        ''')
        
        overall_stats = cursor.fetchone()
        
        summary = {
            'collection_period': {
                'total_days': overall_stats[0] if overall_stats else 0,
                'first_date': overall_stats[3] if overall_stats else None,
                'last_date': overall_stats[4] if overall_stats else None
            },
            'averages': {
                'sites_per_day': round(overall_stats[1], 1) if overall_stats and overall_stats[1] else 0,
                'players_per_day': round(overall_stats[2], 0) if overall_stats and overall_stats[2] else 0
            },
            'recent_collections': []
        }
        
        for stat in recent_stats:
            summary['recent_collections'].append({
                'date': stat[0],
                'sites': stat[1],
                'gg_poker_sites': stat[2],
                'total_players': stat[3],
                'cash_players': stat[4]
            })
        
        conn.close()
        return summary

def main():
    """ìš´ì˜ìš© ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰"""
    print("ğŸ¯ ìš´ì˜ìš© í¬ì»¤ ì‚¬ì´íŠ¸ ë°ì´í„° ìˆ˜ì§‘ê¸°")
    print("=" * 60)
    
    collector = ProductionDataCollector()
    
    # ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰
    success = collector.run_daily_collection()
    
    if success:
        print("\nğŸ“Š ìˆ˜ì§‘ í˜„í™© ìš”ì•½")
        print("-" * 40)
        summary = collector.get_collection_summary()
        
        print(f"ì´ ìˆ˜ì§‘ ì¼ìˆ˜: {summary['collection_period']['total_days']}ì¼")
        print(f"ì¼í‰ê·  ì‚¬ì´íŠ¸: {summary['averages']['sites_per_day']}ê°œ")
        print(f"ì¼í‰ê·  í”Œë ˆì´ì–´: {summary['averages']['players_per_day']:,.0f}ëª…")
        
        if summary['recent_collections']:
            print(f"\nğŸ“… ìµœê·¼ ìˆ˜ì§‘ ë‚´ì—­:")
            for collection in summary['recent_collections'][:5]:
                print(f"  {collection['date']}: {collection['sites']}ê°œ ì‚¬ì´íŠ¸, {collection['total_players']:,}ëª…")
        
        print(f"\nğŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ğŸ“ˆ GG POKER ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê°€ë™ ì¤‘")
        print(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤: {collector.db_path}")
        
    else:
        print(f"\nğŸ’€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ - ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”")
    
    return success

if __name__ == "__main__":
    main()