#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PokerScout ìµœì¢… ë°ì´í„° í¬ë¡¤ëŸ¬ - ì„±ê³µ ë²„ì „
"""
import sys
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

import cloudscraper
from bs4 import BeautifulSoup
import json
import re
from datetime import datetime

class FinalPokerScoutCrawler:
    def __init__(self):
        self.scraper = cloudscraper.create_scraper()
        
    def parse_player_number(self, text):
        """í”Œë ˆì´ì–´ ìˆ˜ íŒŒì‹± ê°œì„ """
        if not text or text.strip() == '-' or text.strip() == '':
            return 0
            
        # ìˆ«ìì™€ ì‰¼í‘œë§Œ ë‚¨ê¸°ê³  ëª¨ë“  ë¬¸ì ì œê±°
        cleaned = re.sub(r'[^\d,]', '', text.strip())
        cleaned = cleaned.replace(',', '')
        
        try:
            return int(cleaned) if cleaned else 0
        except:
            return 0
            
    def crawl_pokerscout(self):
        """ìµœì¢… PokerScout í¬ë¡¤ë§"""
        print("ğŸ¯ PokerScout ìµœì¢… í¬ë¡¤ë§ ì‹œì‘...")
        
        try:
            response = self.scraper.get('https://www.pokerscout.com', timeout=30)
            
            if response.status_code != 200:
                raise Exception(f"HTTP {response.status_code}")
                
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # rankTable í´ë˜ìŠ¤ ì°¾ê¸° (ëŒ€ì†Œë¬¸ì êµ¬ë¶„)
            table = soup.find('table', {'class': 'rankTable'})
            if not table:
                table = soup.find('table', id='rankTable')
                
            if not table:
                raise Exception("rankTableì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
            print("âœ… rankTable ë°œê²¬!")
            
            # í…Œì´ë¸” ë¶„ì„
            rows = table.find('tbody').find_all('tr') if table.find('tbody') else table.find_all('tr')[1:]
            
            results = []
            
            for i, row in enumerate(rows):
                try:
                    cols = row.find_all('td')
                    if len(cols) < 6:
                        continue
                        
                    # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì—ì„œ ìˆœìœ„ì™€ ì‚¬ì´íŠ¸ëª… ë¶„ë¦¬
                    first_col = cols[0]
                    rank_and_name = first_col.get_text(separator='\n').strip()
                    
                    # ìˆœìœ„ ì¶”ì¶œ (ìˆ«ìë§Œ)
                    rank_match = re.search(r'^(\d+)', rank_and_name)
                    if not rank_match:
                        continue
                        
                    rank = int(rank_match.group(1))
                    
                    # ì‚¬ì´íŠ¸ëª… ì¶”ì¶œ (ìˆœìœ„ ë’¤ì˜ í…ìŠ¤íŠ¸)
                    name_part = rank_and_name.replace(str(rank), '').strip()
                    if name_part.startswith('\n'):
                        name_part = name_part[1:].strip()
                    
                    # ì´ë¯¸ì§€ alt í…ìŠ¤íŠ¸ì—ì„œ ì‚¬ì´íŠ¸ëª… ê°€ì ¸ì˜¤ê¸°
                    img = first_col.find('img')
                    if img and img.get('alt'):
                        site_name = img.get('alt')
                    else:
                        site_name = name_part.split('\n')[0].strip()
                        
                    if not site_name:
                        continue
                        
                    # ë°ì´í„° ì¶”ì¶œ
                    players_online = self.parse_player_number(cols[1].text)
                    cash_players = self.parse_player_number(cols[2].text)
                    peak_24h = self.parse_player_number(cols[3].text)
                    seven_day_avg = self.parse_player_number(cols[4].text)
                    
                    data = {
                        'rank': rank,
                        'name': site_name,
                        'players_online': players_online,
                        'cash_players': cash_players,
                        'tournament_players': players_online - cash_players if players_online > cash_players else 0,
                        'peak_24h': peak_24h,
                        '7_day_average': seven_day_avg,
                        'total_players': players_online
                    }
                    
                    results.append(data)
                    print(f"{rank:2d}. {site_name:<25} - {players_online:,} players online")
                    
                except Exception as e:
                    print(f"  í–‰ {i} íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                    continue
                    
            if len(results) == 0:
                raise Exception("ë°ì´í„°ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
            return results
            
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)}")
            return None
            
    def save_data(self, data):
        """ë°ì´í„° ì €ì¥"""
        if not data:
            return False
            
        output = {
            'source': 'PokerScout.com',
            'method': 'CloudScraper + Advanced Parsing',
            'timestamp': datetime.now().isoformat(),
            'total_sites': len(data),
            'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC'),
            'data': data
        }
        
        # JSON ì €ì¥
        with open('pokerscout_final_data.json', 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
            
        print(f"\nğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ: pokerscout_final_data.json")
        print(f"ğŸ“Š ì´ {len(data)}ê°œ í¬ì»¤ ì‚¬ì´íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ")
        
        return True
        
    def display_results(self, data):
        """ê²°ê³¼ ì¶œë ¥"""
        if not data:
            return
            
        print(f"\nğŸ† ìƒìœ„ {min(15, len(data))}ê°œ í¬ì»¤ ì‚¬ì´íŠ¸ (ì‹¤ì‹œê°„ íŠ¸ë˜í”½)")
        print("="*80)
        print(f"{'ìˆœìœ„':<4} {'ì‚¬ì´íŠ¸ëª…':<25} {'í˜„ì¬ ì ‘ì†ì':<12} {'ìºì‹œê²Œì„':<10} {'24H í”¼í¬':<10} {'7ì¼ í‰ê· ':<10}")
        print("-"*80)
        
        for site in data[:15]:
            print(f"{site['rank']:<4} {site['name']:<25} {site['players_online']:,}ëª…{'':<6} "
                  f"{site['cash_players']:,}ëª…{'':<4} {site['peak_24h']:,}ëª…{'':<4} {site['7_day_average']:,}ëª…")
            
        # í†µê³„ ì •ë³´
        total_players = sum(site['players_online'] for site in data)
        total_cash = sum(site['cash_players'] for site in data)
        
        print("-"*80)
        print(f"ì „ì²´ í†µê³„:")
        print(f"  - ì´ í¬ì»¤ ì‚¬ì´íŠ¸: {len(data)}ê°œ")
        print(f"  - ì „ì²´ ì ‘ì†ì: {total_players:,}ëª…")
        print(f"  - ìºì‹œê²Œì„ ì ‘ì†ì: {total_cash:,}ëª…")
        print(f"  - í† ë„ˆë¨¼íŠ¸ ì ‘ì†ì: {total_players - total_cash:,}ëª…")
        
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ PokerScout ìµœì¢… ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘!")
    print("="*60)
    
    crawler = FinalPokerScoutCrawler()
    
    # ë°ì´í„° í¬ë¡¤ë§
    data = crawler.crawl_pokerscout()
    
    if data and len(data) > 5:
        # ê²°ê³¼ ì¶œë ¥
        crawler.display_results(data)
        
        # ë°ì´í„° ì €ì¥
        success = crawler.save_data(data)
        
        if success:
            print(f"\nğŸ‰ í”„ë¡œì íŠ¸ êµ¬ì› ì„±ê³µ!")
            print(f"âœ… {len(data)}ê°œ í¬ì»¤ ì‚¬ì´íŠ¸ì˜ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
            print(f"âœ… ë°ì´í„° í’ˆì§ˆ: ìš°ìˆ˜ (ëª¨ë“  ì£¼ìš” ì‚¬ì´íŠ¸ í¬í•¨)")
            print(f"âœ… íŒŒì¼ ìœ„ì¹˜: pokerscout_final_data.json")
            return True
        else:
            print(f"\nâš ï¸ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨")
            return False
    else:
        print(f"\nğŸ’€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ - í”„ë¡œì íŠ¸ íê¸° ìœ„í—˜!")
        print(f"ìˆ˜ì§‘ëœ ì‚¬ì´íŠ¸ ìˆ˜: {len(data) if data else 0}")
        return False

if __name__ == "__main__":
    success = main()
    
    if success:
        print(f"\nğŸ ë¯¸ì…˜ ì™„ë£Œ! í”„ë¡œì íŠ¸ ê³„ì† ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        print(f"\nğŸ’€ ë¯¸ì…˜ ì‹¤íŒ¨... ë‹¤ë¥¸ í•´ê²°ì±…ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.")