#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PokerScout ë°ì´í„° ìˆ˜ì§‘ - ë‹¨ìˆœí™”ëœ ë²„ì „
"""
import sys
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

import requests
import cloudscraper
from bs4 import BeautifulSoup
import time
import json
from datetime import datetime
import random

class PokerScoutHunter:
    def __init__(self):
        self.session = requests.Session()
        
    def parse_table_data(self, soup):
        """í…Œì´ë¸” ë°ì´í„° íŒŒì‹±"""
        table = soup.find('table', {'class': 'ranktable'})
        if not table:
            # ë‹¤ë¥¸ ê°€ëŠ¥í•œ ì„ íƒìë“¤ ì‹œë„
            table = soup.find('table', id='ranktable')
            if not table:
                table = soup.find('table', {'id': 'rankings'})
            if not table:
                tables = soup.find_all('table')
                for t in tables:
                    if 'rank' in str(t).lower() or 'poker' in str(t).lower():
                        table = t
                        break
                        
        if not table:
            print("í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        rows = table.find_all('tr')
        if len(rows) < 2:
            print("ë°ì´í„° í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        results = []
        header_found = False
        
        for row in rows:
            cols = row.find_all(['td', 'th'])
            if len(cols) >= 5:  # ìµœì†Œ 5ê°œ ì»¬ëŸ¼
                # í—¤ë” ìŠ¤í‚µ
                if not header_found and any('rank' in col.text.lower() for col in cols):
                    header_found = True
                    continue
                    
                if header_found or len(results) == 0:  # ì²« ë°ì´í„° í–‰ë¶€í„°
                    try:
                        data = {
                            'rank': self.parse_number(cols[0].text.strip()) or len(results) + 1,
                            'name': cols[1].text.strip(),
                            'cash_players': self.parse_number(cols[2].text.strip()) if len(cols) > 2 else 0,
                            'tournament_players': self.parse_number(cols[3].text.strip()) if len(cols) > 3 else 0,
                            'total_players': self.parse_number(cols[4].text.strip()) if len(cols) > 4 else 0,
                            '7_day_average': self.parse_number(cols[5].text.strip()) if len(cols) > 5 else 0
                        }
                        
                        # ìœ íš¨í•œ ë°ì´í„°ì¸ì§€ í™•ì¸
                        if data['name'] and len(data['name']) > 1:
                            results.append(data)
                            
                    except Exception as e:
                        continue
                        
        return results if results else None
        
    def parse_number(self, text):
        """ìˆ«ì íŒŒì‹±"""
        if not text or text == '-' or text == '':
            return 0
        text = text.replace(',', '').replace(' ', '').replace('players', '')
        try:
            return int(float(text))
        except:
            return 0
            
    def method_cloudscraper(self):
        """CloudScraper ë°©ë²•"""
        print("\n=== CloudScraper ì‹œë„ ===")
        try:
            scraper = cloudscraper.create_scraper(
                browser={'browser': 'chrome', 'platform': 'windows', 'mobile': False}
            )
            
            print("PokerScout ì ‘ì† ì¤‘...")
            response = scraper.get('https://www.pokerscout.com', timeout=30)
            
            print(f"ì‘ë‹µ ì½”ë“œ: {response.status_code}")
            print(f"ì‘ë‹µ í¬ê¸°: {len(response.content)} bytes")
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # í˜ì´ì§€ ë‚´ìš© í™•ì¸
                if 'cloudflare' in response.text.lower():
                    print("Cloudflare ì°¨ë‹¨ ê°ì§€ë¨")
                    return None
                    
                results = self.parse_table_data(soup)
                if results and len(results) > 0:
                    print(f"âœ“ ì„±ê³µ! {len(results)}ê°œ ì‚¬ì´íŠ¸ ë°œê²¬")
                    return results
                else:
                    print("ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨ - HTML êµ¬ì¡° í™•ì¸")
                    # HTML ì¼ë¶€ ì¶œë ¥
                    print("\nHTML ìƒ˜í”Œ:")
                    print(response.text[:1000])
            else:
                print(f"HTTP ì˜¤ë¥˜: {response.status_code}")
                
        except Exception as e:
            print(f"ì˜¤ë¥˜: {str(e)}")
        return None
        
    def method_mobile_headers(self):
        """ëª¨ë°”ì¼ í—¤ë”ë¡œ ì‹œë„"""
        print("\n=== ëª¨ë°”ì¼ í—¤ë” ì‹œë„ ===")
        
        mobile_agents = [
            'Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X) AppleWebKit/605.1.15',
            'Mozilla/5.0 (Android 11; Mobile; rv:83.0) Gecko/83.0 Firefox/83.0',
            'Mozilla/5.0 (Linux; Android 11; SM-G991B) AppleWebKit/537.36'
        ]
        
        for agent in mobile_agents:
            try:
                headers = {
                    'User-Agent': agent,
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.5',
                    'Accept-Encoding': 'gzip, deflate',
                    'Connection': 'keep-alive'
                }
                
                print(f"ì‹œë„ ì¤‘: {agent[:50]}...")
                response = requests.get('https://www.pokerscout.com', headers=headers, timeout=15)
                
                if response.status_code == 200:
                    soup = BeautifulSoup(response.content, 'html.parser')
                    results = self.parse_table_data(soup)
                    if results:
                        print(f"âœ“ ëª¨ë°”ì¼ ì ‘ê·¼ ì„±ê³µ! {len(results)}ê°œ ì‚¬ì´íŠ¸")
                        return results
                        
                time.sleep(2)
                
            except Exception as e:
                print(f"  ì‹¤íŒ¨: {str(e)}")
                
        return None
        
    def method_wayback_machine(self):
        """Wayback Machine ì‹œë„"""
        print("\n=== Wayback Machine ì‹œë„ ===")
        try:
            # ìµœì‹  ìŠ¤ëƒ…ìƒ· ì°¾ê¸°
            api_url = "http://archive.org/wayback/available?url=pokerscout.com"
            response = requests.get(api_url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                if 'archived_snapshots' in data and 'closest' in data['archived_snapshots']:
                    snapshot_url = data['archived_snapshots']['closest']['url']
                    timestamp = data['archived_snapshots']['closest']['timestamp']
                    
                    print(f"ìŠ¤ëƒ…ìƒ· ë°œê²¬: {timestamp}")
                    print(f"URL: {snapshot_url}")
                    
                    # ìŠ¤ëƒ…ìƒ· ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    snapshot_response = requests.get(snapshot_url, timeout=15)
                    if snapshot_response.status_code == 200:
                        soup = BeautifulSoup(snapshot_response.content, 'html.parser')
                        results = self.parse_table_data(soup)
                        if results:
                            print(f"âœ“ Wayback Machine ì„±ê³µ! {len(results)}ê°œ ì‚¬ì´íŠ¸")
                            return results
                            
        except Exception as e:
            print(f"Wayback Machine ì˜¤ë¥˜: {str(e)}")
            
        return None
        
    def method_google_cache(self):
        """Google Cache ì‹œë„"""
        print("\n=== Google Cache ì‹œë„ ===")
        try:
            cache_url = "https://webcache.googleusercontent.com/search?q=cache:www.pokerscout.com"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(cache_url, headers=headers, timeout=15)
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                results = self.parse_table_data(soup)
                if results:
                    print(f"âœ“ Google Cache ì„±ê³µ! {len(results)}ê°œ ì‚¬ì´íŠ¸")
                    return results
                    
        except Exception as e:
            print(f"Google Cache ì˜¤ë¥˜: {str(e)}")
            
        return None
        
    def method_direct_with_delay(self):
        """ì§€ì—°ì‹œê°„ì„ ë‘ê³  ì§ì ‘ ì ‘ê·¼"""
        print("\n=== ì§€ì—° ì ‘ê·¼ ì‹œë„ ===")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        }
        
        session = requests.Session()
        session.headers.update(headers)
        
        try:
            # ì²« ë°©ë¬¸ (ì¿ í‚¤ ì„¤ì •)
            print("ì²« ë°©ë¬¸ - ì¿ í‚¤ ì„¤ì •...")
            response1 = session.get('https://www.pokerscout.com', timeout=15)
            print(f"ì²« ë°©ë¬¸ ì‘ë‹µ: {response1.status_code}")
            
            # ì ì‹œ ëŒ€ê¸°
            time.sleep(5)
            
            # ë‘ ë²ˆì§¸ ë°©ë¬¸
            print("ë‘ ë²ˆì§¸ ë°©ë¬¸...")
            response2 = session.get('https://www.pokerscout.com', timeout=15)
            print(f"ë‘ ë²ˆì§¸ ë°©ë¬¸ ì‘ë‹µ: {response2.status_code}")
            
            if response2.status_code == 200:
                soup = BeautifulSoup(response2.content, 'html.parser')
                results = self.parse_table_data(soup)
                if results:
                    print(f"âœ“ ì§€ì—° ì ‘ê·¼ ì„±ê³µ! {len(results)}ê°œ ì‚¬ì´íŠ¸")
                    return results
                    
        except Exception as e:
            print(f"ì§€ì—° ì ‘ê·¼ ì˜¤ë¥˜: {str(e)}")
            
        return None
        
    def hunt_data(self):
        """ëª¨ë“  ë°©ë²• ì‹œë„"""
        print("ğŸ¯ PokerScout ë°ì´í„° í—ŒíŒ… ì‹œì‘!")
        print("="*60)
        
        methods = [
            ("CloudScraper", self.method_cloudscraper),
            ("ëª¨ë°”ì¼ í—¤ë”", self.method_mobile_headers),
            ("ì§€ì—° ì ‘ê·¼", self.method_direct_with_delay),
            ("Google Cache", self.method_google_cache),
            ("Wayback Machine", self.method_wayback_machine)
        ]
        
        for method_name, method_func in methods:
            print(f"\nğŸ” {method_name} ì‹œë„ ì¤‘...")
            try:
                results = method_func()
                if results and len(results) > 0:
                    print(f"\nğŸ‰ ì„±ê³µ! {method_name}ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
                    
                    # ê²°ê³¼ ì €ì¥
                    output = {
                        'source': 'PokerScout.com',
                        'method': method_name,
                        'timestamp': datetime.now().isoformat(),
                        'total_sites': len(results),
                        'data': results
                    }
                    
                    with open('pokerscout_real_data.json', 'w', encoding='utf-8') as f:
                        json.dump(output, f, indent=2, ensure_ascii=False)
                    
                    print(f"\nğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ: pokerscout_real_data.json")
                    print(f"ğŸ“Š ìˆ˜ì§‘ëœ ì‚¬ì´íŠ¸ ìˆ˜: {len(results)}")
                    
                    print("\nğŸ† ìƒìœ„ 10ê°œ í¬ì»¤ ì‚¬ì´íŠ¸:")
                    for i, site in enumerate(results[:10]):
                        players = site['total_players']
                        avg = site['7_day_average']
                        print(f"{site['rank']:2d}. {site['name']:<20} - {players:,} players (7ì¼ í‰ê· : {avg:,})")
                    
                    return True
                else:
                    print(f"âŒ {method_name} ì‹¤íŒ¨")
                    
            except Exception as e:
                print(f"âŒ {method_name} ì˜¤ë¥˜: {str(e)}")
                
            # ë°©ë²• ê°„ íœ´ì‹
            time.sleep(3)
            
        print("\nğŸ’€ ëª¨ë“  ë°©ë²• ì‹¤íŒ¨... í”„ë¡œì íŠ¸ íê¸° ìœ„ê¸°!")
        return False

if __name__ == "__main__":
    hunter = PokerScoutHunter()
    success = hunter.hunt_data()
    
    if success:
        print("\nâœ… í”„ë¡œì íŠ¸ êµ¬ì¶œ ì„±ê³µ!")
    else:
        print("\nğŸ’€ í”„ë¡œì íŠ¸ íê¸°...")
        print("\nìµœí›„ì˜ ìˆ˜ë‹¨:")
        print("1. VPN ì‚¬ìš©")
        print("2. ë‹¤ë¥¸ ë„¤íŠ¸ì›Œí¬ì—ì„œ ì‹œë„")
        print("3. PokerScout ìš´ì˜ì§„ì—ê²Œ API ì•¡ì„¸ìŠ¤ ìš”ì²­")