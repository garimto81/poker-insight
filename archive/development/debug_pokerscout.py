#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PokerScout HTML êµ¬ì¡° ë¶„ì„ ë° ë””ë²„ê¹…
"""
import sys
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

import cloudscraper
from bs4 import BeautifulSoup
import json
from datetime import datetime

def analyze_pokerscout_structure():
    """PokerScout í˜ì´ì§€ êµ¬ì¡° ë¶„ì„"""
    print("ğŸ” PokerScout í˜ì´ì§€ êµ¬ì¡° ë¶„ì„ ì¤‘...")
    
    try:
        scraper = cloudscraper.create_scraper()
        response = scraper.get('https://www.pokerscout.com', timeout=30)
        
        if response.status_code == 200:
            print(f"âœ… ì ‘ì† ì„±ê³µ! ì‘ë‹µ í¬ê¸°: {len(response.content)} bytes")
            
            # HTML íŒŒì¼ë¡œ ì €ì¥
            with open('pokerscout_page.html', 'w', encoding='utf-8') as f:
                f.write(response.text)
            print("ğŸ“„ HTML íŒŒì¼ ì €ì¥: pokerscout_page.html")
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # 1. ëª¨ë“  í…Œì´ë¸” ì°¾ê¸°
            print("\n1. í…Œì´ë¸” êµ¬ì¡° ë¶„ì„:")
            tables = soup.find_all('table')
            print(f"   ì´ {len(tables)}ê°œ í…Œì´ë¸” ë°œê²¬")
            
            for i, table in enumerate(tables):
                print(f"\n   í…Œì´ë¸” {i+1}:")
                print(f"   - í´ë˜ìŠ¤: {table.get('class', 'ì—†ìŒ')}")
                print(f"   - ID: {table.get('id', 'ì—†ìŒ')}")
                rows = table.find_all('tr')
                print(f"   - í–‰ ìˆ˜: {len(rows)}")
                
                if rows:
                    first_row = rows[0]
                    cols = first_row.find_all(['th', 'td'])
                    print(f"   - ì²« í–‰ ì»¬ëŸ¼ ìˆ˜: {len(cols)}")
                    if cols:
                        headers = [col.text.strip() for col in cols]
                        print(f"   - í—¤ë”: {headers}")
            
            # 2. ranktable í´ë˜ìŠ¤ í™•ì¸
            print("\n2. ranktable í´ë˜ìŠ¤ í™•ì¸:")
            ranktable = soup.find('table', {'class': 'ranktable'})
            if ranktable:
                print("   âœ… ranktable ë°œê²¬!")
                analyze_ranktable(ranktable)
            else:
                print("   âŒ ranktable ì—†ìŒ")
                
            # 3. ë‹¤ë¥¸ ê°€ëŠ¥í•œ ì„ íƒìë“¤ í™•ì¸
            print("\n3. ë‹¤ë¥¸ ê°€ëŠ¥í•œ ì„ íƒìë“¤:")
            selectors = [
                ('table[id*="rank"]', 'IDì— rank í¬í•¨'),
                ('table[class*="rank"]', 'í´ë˜ìŠ¤ì— rank í¬í•¨'),
                ('.rankings', 'ë­í‚¹ í´ë˜ìŠ¤'),
                ('#rankings', 'ë­í‚¹ ID'),
                ('div.poker-sites', 'í¬ì»¤ ì‚¬ì´íŠ¸ div'),
                ('.site-list', 'ì‚¬ì´íŠ¸ ëª©ë¡'),
                ('tbody tr', 'í…Œì´ë¸” ë°”ë”” í–‰ë“¤')
            ]
            
            for selector, desc in selectors:
                elements = soup.select(selector)
                if elements:
                    print(f"   âœ… {desc}: {len(elements)}ê°œ ìš”ì†Œ")
                    if selector == 'tbody tr' and len(elements) > 5:
                        print("      tbody tr ë¶„ì„ ì‹œë„...")
                        analyze_tbody_rows(elements)
                else:
                    print(f"   âŒ {desc}: ì—†ìŒ")
                    
            # 4. í…ìŠ¤íŠ¸ì—ì„œ í¬ì»¤ ì‚¬ì´íŠ¸ëª… ì°¾ê¸°
            print("\n4. ì•Œë ¤ì§„ í¬ì»¤ ì‚¬ì´íŠ¸ëª… ê²€ìƒ‰:")
            poker_sites = ['PokerStars', 'GGPoker', '888poker', 'partypoker', 'WPT', 'Americas Cardroom']
            page_text = soup.get_text()
            
            for site in poker_sites:
                if site.lower() in page_text.lower():
                    print(f"   âœ… {site} ë°œê²¬")
                else:
                    print(f"   âŒ {site} ì—†ìŒ")
                    
        else:
            print(f"âŒ ì ‘ì† ì‹¤íŒ¨: HTTP {response.status_code}")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {str(e)}")

def analyze_ranktable(table):
    """ranktable ìƒì„¸ ë¶„ì„"""
    print("   ranktable ìƒì„¸ ë¶„ì„:")
    rows = table.find_all('tr')
    
    for i, row in enumerate(rows[:5]):  # ìƒìœ„ 5ê°œ í–‰ë§Œ
        cols = row.find_all(['th', 'td'])
        print(f"   í–‰ {i+1}: {len(cols)}ê°œ ì»¬ëŸ¼")
        for j, col in enumerate(cols):
            text = col.text.strip()
            print(f"     ì»¬ëŸ¼ {j+1}: '{text}'")

def analyze_tbody_rows(rows):
    """tbody í–‰ë“¤ ë¶„ì„"""
    print("   tbody í–‰ ë¶„ì„:")
    for i, row in enumerate(rows[:3]):  # ìƒìœ„ 3ê°œë§Œ
        cols = row.find_all(['td', 'th'])
        if len(cols) >= 4:
            texts = [col.text.strip() for col in cols]
            print(f"   í–‰ {i+1}: {texts}")

def extract_real_data():
    """ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ ì‹œë„"""
    print("\nğŸ¯ ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ ì‹œë„...")
    
    try:
        scraper = cloudscraper.create_scraper()
        response = scraper.get('https://www.pokerscout.com', timeout=30)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ë°©ë²• 1: ranktable ë‹¤ì‹œ ì‹œë„
            table = soup.find('table', {'class': 'ranktable'})
            if table:
                results = extract_from_ranktable(table)
                if results:
                    return results
                    
            # ë°©ë²• 2: tbody í–‰ë“¤ì—ì„œ ì¶”ì¶œ
            tbody_rows = soup.select('tbody tr')
            if tbody_rows:
                results = extract_from_tbody(tbody_rows)
                if results:
                    return results
                    
            # ë°©ë²• 3: ëª¨ë“  í…Œì´ë¸”ì—ì„œ í¬ì»¤ ë°ì´í„° ì°¾ê¸°
            tables = soup.find_all('table')
            for table in tables:
                results = extract_from_any_table(table)
                if results:
                    return results
                    
    except Exception as e:
        print(f"âŒ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        
    return None

def extract_from_ranktable(table):
    """ranktableì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
    results = []
    rows = table.find_all('tr')
    
    for row in rows[1:]:  # í—¤ë” ìŠ¤í‚µ
        cols = row.find_all('td')
        if len(cols) >= 5:
            try:
                rank_text = cols[0].text.strip()
                name_text = cols[1].text.strip()
                
                # ìˆ«ìê°€ ìˆëŠ” í–‰ë§Œ ì²˜ë¦¬
                if rank_text.isdigit() and name_text and len(name_text) > 2:
                    data = {
                        'rank': int(rank_text),
                        'name': name_text,
                        'cash_players': parse_players(cols[2].text.strip()),
                        'tournament_players': parse_players(cols[3].text.strip()),
                        'total_players': parse_players(cols[4].text.strip()),
                        '7_day_average': parse_players(cols[5].text.strip()) if len(cols) > 5 else 0
                    }
                    results.append(data)
                    
            except:
                continue
                
    return results if len(results) > 5 else None

def extract_from_tbody(rows):
    """tbody í–‰ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
    results = []
    
    for i, row in enumerate(rows):
        cols = row.find_all('td')
        if len(cols) >= 4:
            try:
                # í¬ì»¤ ì‚¬ì´íŠ¸ëª… íŒ¨í„´ ì°¾ê¸°
                name_col = None
                for col in cols:
                    text = col.text.strip()
                    if any(word in text.lower() for word in ['poker', 'gg', '888', 'party', 'stars']):
                        name_col = text
                        break
                        
                if name_col:
                    data = {
                        'rank': i + 1,
                        'name': name_col,
                        'total_players': parse_players(cols[-1].text.strip())
                    }
                    results.append(data)
                    
            except:
                continue
                
    return results if len(results) > 3 else None

def extract_from_any_table(table):
    """ëª¨ë“  í…Œì´ë¸”ì—ì„œ í¬ì»¤ ë°ì´í„° ì°¾ê¸°"""
    rows = table.find_all('tr')
    if len(rows) < 3:  # ìµœì†Œ 3í–‰ í•„ìš”
        return None
        
    results = []
    
    for row in rows:
        cols = row.find_all(['td', 'th'])
        if len(cols) >= 3:
            for col in cols:
                text = col.text.strip()
                # í¬ì»¤ ì‚¬ì´íŠ¸ëª… íŒ¨í„´
                if any(site in text for site in ['PokerStars', 'GGPoker', '888poker', 'partypoker']):
                    # ê°™ì€ í–‰ì—ì„œ ìˆ«ì ì°¾ê¸°
                    numbers = []
                    for c in cols:
                        num = parse_players(c.text.strip())
                        if num > 0:
                            numbers.append(num)
                            
                    if numbers:
                        data = {
                            'rank': len(results) + 1,
                            'name': text,
                            'total_players': max(numbers)
                        }
                        results.append(data)
                        
    return results if len(results) > 2 else None

def parse_players(text):
    """í”Œë ˆì´ì–´ ìˆ˜ íŒŒì‹±"""
    if not text or text == '-':
        return 0
    text = text.replace(',', '').replace(' ', '').replace('players', '')
    try:
        return int(float(text))
    except:
        return 0

if __name__ == "__main__":
    # 1. í˜ì´ì§€ êµ¬ì¡° ë¶„ì„
    analyze_pokerscout_structure()
    
    # 2. ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ
    real_data = extract_real_data()
    
    if real_data:
        print(f"\nğŸ‰ ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ ì„±ê³µ! {len(real_data)}ê°œ ì‚¬ì´íŠ¸")
        
        output = {
            'source': 'PokerScout.com',
            'method': 'Advanced Parsing',
            'timestamp': datetime.now().isoformat(),
            'total_sites': len(real_data),
            'data': real_data
        }
        
        with open('pokerscout_fixed_data.json', 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
            
        print("ğŸ’¾ ìˆ˜ì •ëœ ë°ì´í„° ì €ì¥: pokerscout_fixed_data.json")
        
        for site in real_data[:10]:
            print(f"{site['rank']}. {site['name']} - {site.get('total_players', 0):,} players")
            
    else:
        print("\nâŒ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")
        print("ğŸ” pokerscout_page.html íŒŒì¼ì„ ìˆ˜ë™ìœ¼ë¡œ í™•ì¸í•´ë³´ì„¸ìš”.")